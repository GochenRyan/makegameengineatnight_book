{"./":{"url":"./","title":"Introduction","keywords":"","body":" Copyright © captainchen all right reserved，powered by GitbookFile Modify: 2021-04-28 13:26:25 "},"pages/前言.html":{"url":"pages/前言.html","title":"前言","keywords":"","body":"前言前言 我们每天与游戏引擎打交道，有时候会心痒痒想了解游戏引擎是怎么做的，但是游戏引擎是如此庞大的一个工程，如虚幻这行业至尊，代码量更是复杂到以千万行计，个人想完成一个游戏引擎似乎是不可能的事情。 不如退而求其次，从实现一个简单的游戏引擎入门，然后再深入Unity/Unreal的源码去钻研。 本书拆分游戏引擎的多个模块，到书中的每一章进行讲解，最终实现一个简单的游戏引擎。 本书提供的内容 一个简单的游戏引擎，有各种开源库+引擎逻辑组合而成，本书主要介绍各种开源库的使用方法，以及对它们进行组合的过程。 对从事游戏性能优化工作的开发者也有所帮助，从本书中或许可以找到以下问题的答案： 为什么要合并DrawCall？ 为什么要减少顶点？ 为什么要减少骨骼数量？ 为什么要将图片压缩为不同的格式？ 为什么要烘焙灯光贴图？ 为什么要减少阴影？ 为什么……？ 本书不涉及内容 图形学 物理学 硬件知识 本书正确的学习方式 图书以实战为主，大部分章节都有CLion实例项目，项目路径在章节开头或结尾给出。 个人推荐的学习方式如下： CLion打开项目，编译运行，看看效果。 过一遍代码，断点调试一下。 看一遍章节内容。 再过一遍代码。 资源下载 本书Markdown以及章节配套项目托管在Github、腾讯工蜂上，读书过程中有疑问、发现错误都可以提Issues。 Github：https://github.com/ThisisGame/makegameengineatnight 腾讯工蜂：https://git.code.tencent.com/ThisisGame/makegameengineatnight 鸣谢 Copyright © captainchen all right reserved，powered by GitbookFile Modify: 2021-04-30 13:12:26 "},"pages/1. 游戏引擎框架介绍/1. 游戏引擎框架介绍.html":{"url":"pages/1. 游戏引擎框架介绍/1. 游戏引擎框架介绍.html","title":"1. 游戏引擎框架介绍","keywords":"","body":"1. 游戏引擎框架介绍1. 游戏引擎框架介绍 目前市面上的游戏引擎比较多，商用的有UE/Unity，开源的有OGRE/Cocos等。 多年前，每个游戏公司都有自己的专有引擎，背靠优秀的引擎技术，可以将产品打磨的更加流畅，画面可以做的更加绚丽。 例如13年网易 蜗牛等厂商进军手游，将一大票小型游戏公司压在脚下，又例如今腾讯做出的PUBGM/CODM等超大场景，无不依赖强劲的引擎技术支持。 各大游戏引擎都有着自己的独特之处，相对其他游戏引擎而言，我比较熟悉Unity。 所以后续开发都会学习Unity的一些思想，一些知识点也以Unity进行举例，方便大家进入状态。 Copyright © captainchen all right reserved，powered by GitbookFile Modify: 2021-03-25 11:17:16 "},"pages/1. 游戏引擎框架介绍/1.1 暗中观察unity.html":{"url":"pages/1. 游戏引擎框架介绍/1.1 暗中观察unity.html","title":"1.1 暗中观察unity","keywords":"","body":"1.1 暗中观察unity1.1 暗中观察unity 一个大型的软件，不可能每行代码都自己写，Unity这样一个大型的商用游戏引擎，也依赖特别多的开源库。 点击Unity菜单的 Help - Software Licensee，就会打开Unity使用的三方库版权声明文件。 这里面很多开源库，都是我们后面需要用到的，例如 字体引擎freetype2、stb单头文件库、fmod音效库、freeimage图片解析库。 这上百个开源库，再加上Unity自己写的逻辑层，就组成了Unity引擎核心部分。 7z Lzma压缩算法，打包Assetbundle用Lzma压缩。 Allegorithmic Substance系列软件协同工作插件，解析PBR材质。 Allocator/tlsf 内存分配管理器，类似的有jemalloc。 Audio/FMOD 3D音效 Audio/fsbtool 解析fsb音效文件 Audio/libvorbis ogg音频解析 Box2D 物理引擎，碰撞检测用。 Cinema4DPlugin Cinema4D导入插件 Clipper 多边形裁剪，http://www.angusj.com/delphi/clipper.php Compression/Brotli 压缩算法 Compression/gzip 压缩算法 Compression/lz4 压缩算法 Compression/lzma 压缩算法 Compression/smol-v SPIR-V压缩工具，SPIR-V是OpenCL和OpenGL的中间语言。 Facebook.CSSLayout CSS语法解析，一般用于UI界面制作。 DirectX DX DotNetZip 压缩 double-conversion double与string相互转换 ExCSS CSS语法解析，https://github.com/Unity-Technologies/ExCSS FBXSDK fbxsdk，Autodesk提供lib，用来从fbx中读取模型数据，然后转换成引擎自定义格式 FreeImage 图片文件解析库 freetype2 ttf字体解析库 google/sparsehash 省内存的hash实现 HashFunctions 各种hash函数 Json.NET json库 JsonParsers json库 libart 基数树 https://github.com/armon/libart/ libcurl 网络库 libjpeg-turbo 解析jpeg库，libjpeg升级版 libpng png解析库 libtess2 细分曲面库 libunwind ibunwind库提供堆栈辗转开解功能。包括用于输出堆栈跟踪的API、用于以编程方式辗转开解堆栈的API以及支持C++异常处理机制的API。 libwebsockets websocket网络库 LMDB Lightning Memory-Mapped Database,就是非常快的内存映射型数据库,LMDB使用内存映射文件,可以提供更好的输入/输出性能 MeshOptimizer Mesh优化 mikktspace 切线空间和法线生成的标准。这个名字是Mikkelsen切线空间的缩写。 Mongoose 嵌入式Web服务器 https://github.com/cesanta/mongoose Mono 开源c#虚拟机 Mono.Cecil Mono.Options MonoBleedingEdge MonoConsolesStandalone MonoResources Nasm 汇编环境 Ndecompiler .net 反编译 https://github.com/Unity-Technologies/ILSpy/tree/unity NiceIO 一套文件读写接口 https://github.com/scottbilas/NiceIO Ninject IOC框架 nodejs nodejs NRefactory 反射c#代码的库 openexr OpenEXR，或简称为exr格式，是一种开放标准的高动态范围图像格式 OpenRL 全称Open Ray Tracing Language，开放光线追踪语言 OpenSSL 加密算法库 optool ios代码注入库 https://github.com/alexzielenski/optool ParserGenerators 一套语法解析库 PhysX3 physx物理加速驱动 PLCrashReporter ios崩溃日志收集 https://github.com/microsoft/plcrashreporter postgresql postgresql数据库 ProphecySDK 一套多媒体库，提供模型加载、图片解析、键盘鼠标接口 https://www.twilight3d.com/ pubnub 用于聊天的库 pubnub是一家提供反馈信息收集的公司 https://www.pubnub.com/ qmc QMC，全名是Quasi-Monte Carlo（准蒙特卡罗)，这其实是纯蒙特卡罗算法的一个变种 Qt 开源C++ GUI框架，历史悠久。 RakNet 开源网络库，Facebook收购。 RapidJSON 腾讯开源的Json库。 Recast 使用navmesh作为模型的库，支持建网格、寻路、添加动态障碍、群体寻路等特性 https://github.com/recastnavigation/recastnavigation renderdoc 开源的渲染分析工具 Roslyn 代码静态分析工具 SDL2 跨平台的多媒体库,提供了针对音频、视频、键盘、鼠标、控制杆及3D硬件的低级别的访问接口。 ShaderCompilers cg代码编译工具，将unityshader转hlsl，glsl等gpu程序代码。 SketchUp SketchUp导入插件 SonarQube 代码静态分析工具 SpeedTree Speedtree是由SpeedTree Modeler、SpeedTree Compiler和SpeedTree SDK三部分构成的一款三维树木建模的软件 sqlite 嵌入式数据库 stb stb 是由一个个单文件组成的 C/C++ 库。其中包含音频处理、图形处理、3D图形处理、游戏开发、数学库、解析器等。 tetgen TetGen 是一款网格剖分的软件，可以生成高质量的非结构四面体网格,可以用来切割模型。https://www.xuebuyuan.com/2190962.html TextureCompressors 压缩图片工具集合 etc/etc2/pvr/astc theora Theora 是一个开源的视频编解码器，属于Ogg项目的一部分。 ThreadSanitizer ThreadSanitizer(TSAN)是一种C/C++数据竞争检测工具。https://blog.csdn.net/itcomeghgh/article/details/78711039 tinyexr 单个头文件的OpenEXR解析库 https://github.com/syoyo/tinyexr TinyXML xml解析库 Tristripper 三角形条带化 udis86 反汇编引擎 umbra 好像是做遮挡剔除的 UsymTool Unity Symbol Tool，转换symbols (PDB, Mach-O and ELF)为通用格式，用来做崩溃日志收集。 https://gitlab-prod1.eu-cph-1.unityops.net/cloudservices/unitycloud-go-crash VersionControl 版本管理svn videoInput win平台的视频捕捉库 https://github.com/ofTheo/videoInput vpx 一套多媒体库 https://github.com/webmproject/libvpx vrpn vr设备网络库 https://github.com/vrpn/vrpn Vulkan 下一代OpenGL图形库 websockify websocket库 https://github.com/novnc/websockify Wintermute Imagination Technologies开发的OpenRL驱动 xercesc xml解析库 http://xerces.apache.org/xerces-c/ xsec Apache XML安全性库 yaml yaml解析库，prefab就是一个yaml格式文件 Yasm 汇编 zlib 压缩库 Copyright © captainchen all right reserved，powered by GitbookFile Modify: 2021-04-15 11:38:59 "},"pages/1. 游戏引擎框架介绍/1.2 游戏引擎组成.html":{"url":"pages/1. 游戏引擎框架介绍/1.2 游戏引擎组成.html","title":"1.2 游戏引擎组成","keywords":"","body":"1.2 游戏引擎组成1.2 游戏引擎组成 一个游戏引擎，大致分为4层，下面列出来Unity作为对比。 引擎结构 Unity 引擎框架层（脚本） UnityEngine C# 脚本引擎 Unity Mono Wrap 引擎框架层（C++） Unity Native + Depends 底层图形库 底层图形库 Unity引擎的大致结构如下图： 后续我们自己编写的游戏引擎，结构如下： 麻雀虽小，五脏俱全。 Copyright © captainchen all right reserved，powered by GitbookFile Modify: 2021-03-25 11:17:16 "},"pages/2. Opengl开发环境搭建/2. Opengl开发环境搭建.html":{"url":"pages/2. Opengl开发环境搭建/2. Opengl开发环境搭建.html","title":"2. Opengl开发环境搭建","keywords":"","body":"2. Opengl开发环境搭建2. Opengl开发环境搭建 Copyright © captainchen all right reserved，powered by GitbookFile Modify: 2021-03-25 11:17:16 "},"pages/2. Opengl开发环境搭建/2.1 Opengl到底是什么.html":{"url":"pages/2. Opengl开发环境搭建/2.1 Opengl到底是什么.html","title":"2.1 Opengl到底是什么","keywords":"","body":"2.1 Opengl到底是什么opengl是一套规范。为什么选择OpenGL2.1 Opengl到底是什么 opengl是一套规范。 opengl是一套规范，这套规范制定了一些opengl的API 和 shader 语法。 这里我可以用大家熟悉的C#来作为对比，C#也是一套规范，制定了基本的API 和 语法规则，但是在API之下，具体的实现，是可以不同的。 微软对C#的实现是C#.net，我们在Unity里用到的C#实现，是C# mono。 opengl这套规范也是如此，API的具体实现是交给显卡厂商的，Intel的集成显卡可能是这样实现的，英伟达的显卡确是另外的一套实现。 在保证实现规范里的API之后，显卡厂商会自己再进行一些扩展，添加一些高性能的特有的API，这种API一般以EXT标记。 所以当我们打开一个Unity 编译好的shader，会看到里面有很多判断用来区分显卡厂商，这是Unity在尝试使用显卡厂商最新添加的扩展API，以获得最高的性能。 可以到维基百科查看更官方的介绍以及opengl的历史发展：https://en.wikipedia.org/wiki/OpenGL 为什么选择OpenGL opengl已经是上一个时代的产物，opengl的下一个版本是Vulkan，与最新的DX，Metal齐头并进。 但是我们并不会花太多时间在图形库上，所以学习任何一种图形库都是可以的。 之所以选择opengl，是因为opengl是目前唯一支持所有平台的图形库，这样可以更快速的完成引擎的第一个版本。 Copyright © captainchen all right reserved，powered by GitbookFile Modify: 2021-04-26 21:54:32 "},"pages/2. Opengl开发环境搭建/2.2 搭建Opengl开发环境.html":{"url":"pages/2. Opengl开发环境搭建/2.2 搭建Opengl开发环境.html","title":"2.2 搭建Opengl开发环境","keywords":"","body":"2.2 搭建Opengl开发环境1.下载glfw2.配置CLion项目3.这就是OpenGL4.示例下载5.参考文档2.2 搭建Opengl开发环境 如果要自己一行一行代码去创建opengl环境，比较麻烦，opengl官网推荐了很多开源库，几行代码就可以创建opengl环境。 我这里选择 glfw 。 1.下载glfw glfw的下载地址 https://www.glfw.org/download.html 在download 页面，选择 对应系统文件 下载。 2.配置CLion项目 首先安装好Mingw+CLion，先安装Mingw，再安装CLion打开后会自动识别。 Mingw下载地址：http://sourceforge.net/projects/mingw-w64/files/Toolchains%20targetting%20Win32/Personal%20Builds/mingw-builds/installer/mingw-w64-install.exe/download CLion下载地址；https://www.jetbrains.com/clion/ 用CLion新建一个C++项目，然后复制下面的代码到 main.cpp 中。 //main.cpp #include int main(void) { GLFWwindow* window; /* 初始化glfw */ if (!glfwInit()) return -1; /* 创建一个Window 和 OpenGL上下文 */ window = glfwCreateWindow(640, 480, \"Hello World\", NULL, NULL); if (!window) { //创建失败就退出 glfwTerminate(); return -1; } /* 激活上面创建的OpenGL上下文 */ glfwMakeContextCurrent(window); /* 进入游戏引擎主循环 */ while (!should_close(window)) { /* Render here */ glClear(GL_COLOR_BUFFER_BIT); /* Swap front and back buffers */ glfwSwapBuffers(window); /* 处理鼠标 键盘事件 */ glfwPollEvents(); } glfwTerminate(); return 0; } 如下图 这个时候编译不通过的，还没有添加 glfw lib库和头文件引用。 CLion中的依赖库全部在 CMakeLists.txt 中进行配置。 修改如下： #CMakeLists.txt cmake_minimum_required(VERSION 3.17) project(untitled) set(CMAKE_CXX_STANDARD 17) #头文件目录 include_directories(\"glfw-3.3.3.bin.WIN64/include\") #链接文件目录 link_directories(\"glfw-3.3.3.bin.WIN64/lib-static-ucrt\") #链接库 link_libraries(opengl32 glfw3dll) #源代码文件 add_executable(untitled main.cpp) 如下图 这个时候可以编译通过了。但是运行不了，因为缺失dll文件。 拷贝 glfw-3.3.3.bin.WIN64\\lib-static-ucrt\\glfw3.dll 到 cmake-build-debug 目录，如下图： 运行，得到一个空的OpenGL窗口(Unity蓝)。 3.这就是OpenGL 上面得到的黑窗口，就是OpenGL的 Hello World！，在这上面慢慢进行扩展，就进入到更绚丽的游戏世界。 仔细观察代码，理解OpenGL的工作流程。 create_window_context=>start: 创建Window 上下文 make_current_window_context=>inputoutput: 绑定Window 上下文 main_loop=>inputoutput: 进入主循环 should_close=>condition: 是否退出循环 render=>inputoutput: 渲染 swapbuffer=>inputoutput: 交换缓冲区 pollevent=>inputoutput: 处理IO end=>end: 结束 create_window_context->make_current_window_context->main_loop->should_close should_close(yes)->end should_close(no)->render(right)->swapbuffer(right)->pollevent(right)->should_close 4.示例下载 CLion项目文件存放在 samples\\glfw_empty_window\\untitled 目录中，直接用CLion打开即可。 5.参考文档 glfw官方教程 https://www.glfw.org/documentation.html Copyright © captainchen all right reserved，powered by GitbookFile Modify: 2021-03-26 11:20:28 "},"pages/3. 绘制简单图形/3. 绘制简单图形.html":{"url":"pages/3. 绘制简单图形/3. 绘制简单图形.html","title":"3. 绘制简单图形","keywords":"","body":"3. 绘制简单图形3. 绘制简单图形 三角形是游戏世界的基石，你所看到的游戏模型、UI都是基于三角形着色显示出来的。 这一章我们从绘制一个三角形开始，再绘制2个三角形组成正方形，再由绘制一个立方体作为收尾，渐渐加深对OpenGL的印象。 Copyright © captainchen all right reserved，powered by GitbookFile Modify: 2021-04-02 11:26:42 "},"pages/3. 绘制简单图形/3.1 画个三角形.html":{"url":"pages/3. 绘制简单图形/3.1 画个三角形.html","title":"3.1 画个三角形","keywords":"","body":"3.1 画个三角形1. 项目结构2. 顶点数据3. 着色器代码4.主逻辑3.1 画个三角形 CLion项目文件位于 samples\\draw_polygon\\draw_triangle\\untitled 就如同编程语言的hello world!，OpenGL的最佳入门范例就是绘制一个三角形，这一节就来做这个。 1. 项目结构 打开CLion项目，如下图： 主要代码文件有3个： 代码文件 main.cpp 主逻辑 VertexData.h 顶点数据(坐标、颜色) ShaderSource.h Shader代码(顶点Shader和片段Shader) depends目录存放依赖库，如下： 依赖库 glfw-3.3.3.bin.WIN64 glfw提供对OpenGL API封装 glm 数学库，提供Vector、Matrix等数据结构运算 2. 顶点数据 VertexData.h 中存放了三角形 三个顶点的坐标数据和颜色数据。 // // Created by captain on 2021/3/25. // 顶点坐标 顶点颜色 // #ifndef UNTITLED_VERTEXDATA_H #define UNTITLED_VERTEXDATA_H #include static const glm::vec3 kPositions[3] = { glm::vec3{ -1.0f, -1.0f,0.0f}, glm::vec3{ 1.0f, -1.0f,0.0f}, glm::vec3{ 0.f, 1.0f,0.0f} }; static const glm::vec4 kColors[3] = { glm::vec4{ 1.f, 0.f, 0.f ,1.f}, glm::vec4{ 0.f, 1.f, 0.f ,1.f}, glm::vec4{ 0.f, 0.f, 1.f ,1.f} }; #endif //UNTITLED_VERTEXDATA_H 可以修改kPositions和kColors数值查看效果。 3. 着色器代码 ShaderSource.h 中存放了顶点着色器和片段着色器代码。 // // Created by captain on 2021/3/25. // #ifndef UNTITLED_SHADERSOURCE_H #define UNTITLED_SHADERSOURCE_H //顶点着色器代码 static const char* vertex_shader_text = \"#version 330\\n\" \"uniform mat4 u_mvp;\\n\" \"layout(location = 0) in vec3 a_pos;\\n\" \"layout(location = 1) in vec4 a_color;\\n\" \"out vec4 v_color;\\n\" \"void main()\\n\" \"{\\n\" \" gl_Position = u_mvp * vec4(a_pos, 1.0);\\n\" \" v_color = a_color;\\n\" \"}\\n\"; //片段着色器代码 static const char* fragment_shader_text = \"#version 330\\n\" \"in vec4 v_color;\\n\" \"layout(location = 0) out vec4 o_fragColor;\\n\" \"void main()\\n\" \"{\\n\" \" o_fragColor = v_color;\\n\" \"}\\n\"; #endif //UNTITLED_SHADERSOURCE_H 着色器是运行在GPU上的程序，顶点着色器和片段着色器作用于渲染的不同阶段。 这里准备好着色器的代码，然后调用OpenGL API进行编译、链接、运行。 可以以 lua 脚本作为参照，方便理解。 着色器在第4章会详细介绍。 4.主逻辑 main.cpp 就是程序主逻辑。 主要分为4个步骤。 OpenGL初始化，创建Window。 初始化着色器。 关联着色器变量和顶点数据 主循环 4.1 OpenGL初始化 //初始化OpenGL void init_opengl() { //设置错误回调 glfwSetErrorCallback(error_callback); if (!glfwInit()) exit(EXIT_FAILURE); glfwWindowHint(GLFW_CONTEXT_VERSION_MAJOR, 2); glfwWindowHint(GLFW_CONTEXT_VERSION_MINOR, 0); //创建窗口 window = glfwCreateWindow(960, 640, \"Simple example\", NULL, NULL); if (!window) { glfwTerminate(); exit(EXIT_FAILURE); } glfwMakeContextCurrent(window); gladLoadGL(glfwGetProcAddress); glfwSwapInterval(1); } 主要就是创建OpenGL窗口，分辨率为 960x640，这里可以改变窗口尺寸看下效果。 值得赞扬的是，glfwCreateWindow指定的宽高，就是实际显示区域的宽高，不包括标题栏。 4.2 初始化着色器 在ShaderSource.h 提供了着色器代码，既然是代码那么就需要进行编译、链接才能运行，初始化着色器就是做这个。 //编译、链接Shader void compile_shader() { //创建顶点Shader vertex_shader = glCreateShader(GL_VERTEX_SHADER); //指定Shader源码 glShaderSource(vertex_shader, 1, &vertex_shader_text, NULL); //编译Shader glCompileShader(vertex_shader); //创建片段Shader fragment_shader = glCreateShader(GL_FRAGMENT_SHADER); //指定Shader源码 glShaderSource(fragment_shader, 1, &fragment_shader_text, NULL); //编译Shader glCompileShader(fragment_shader); //创建GPU程序 program = glCreateProgram(); //附加Shader glAttachShader(program, vertex_shader); glAttachShader(program, fragment_shader); //Link glLinkProgram(program); } 过一遍，断点看看就行，不要深究。 4.3 关联着色器变量和顶点数据 创建好OpenGL窗口、初始化着色器之后，就可以获取着色器的属性ID，与顶点坐标和颜色数据进行关联。 //获取shader属性ID mvp_location = glGetUniformLocation(program, \"u_mvp\"); vpos_location = glGetAttribLocation(program, \"a_pos\"); vcol_location = glGetAttribLocation(program, \"a_color\"); //启用顶点Shader属性(a_pos)，指定与顶点坐标数据进行关联 glEnableVertexAttribArray(vpos_location); glVertexAttribPointer(vpos_location, 3, GL_FLOAT, false, sizeof(glm::vec3), kPositions); //启用顶点Shader属性(a_color)，指定与顶点颜色数据进行关联 glEnableVertexAttribArray(vcol_location); glVertexAttribPointer(vcol_location, 3, GL_FLOAT, false, sizeof(glm::vec4), kColors); 关联好顶点数据后，就可以在主循环里，将顶点上传然后渲染。 4.4 进入主循环 while (!glfwWindowShouldClose(window)) { float ratio; int width, height; glm::mat4 model,view, projection, mvp; //获取画面宽高 glfwGetFramebufferSize(window, &width, &height); ratio = width / (float) height; glViewport(0, 0, width, height); glClear(GL_COLOR_BUFFER_BIT|GL_DEPTH_BUFFER_BIT); glClearColor(49.f/255,77.f/255,121.f/255,1.f); //坐标系变换 glm::mat4 trans = glm::translate(glm::vec3(0,0,0)); //不移动顶点坐标; glm::mat4 rotation = glm::eulerAngleYXZ(glm::radians(0.f), glm::radians(0.f), glm::radians(0.f)); //使用欧拉角旋转; glm::mat4 scale = glm::scale(glm::vec3(2.0f, 2.0f, 2.0f)); //缩放; model = trans*scale*rotation; view = glm::lookAt(glm::vec3(0, 0, 10), glm::vec3(0, 0,0), glm::vec3(0, 1, 0)); projection=glm::perspective(glm::radians(60.f),ratio,1.f,1000.f); mvp=projection*view*model; //指定GPU程序(就是指定顶点着色器、片段着色器) glUseProgram(program); //上传mvp矩阵 glUniformMatrix4fv(mvp_location, 1, GL_FALSE, &mvp[0][0]); //上传顶点数据并进行绘制 glDrawArrays(GL_TRIANGLES, 0, 3); glUseProgram(-1); glfwSwapBuffers(window); glfwPollEvents(); } 主循环主要做3件事： 坐标系转换 上传mvp矩阵 调用 glDrawArrays 上传顶点数据并进行绘制(这就是一个DrawCall完成) 代码断点看两遍，坐标系变换里面的移动、旋转、缩放数值改改看看效果，就差不多了。 Copyright © captainchen all right reserved，powered by GitbookFile Modify: 2021-04-26 14:49:02 "},"pages/3. 绘制简单图形/3.2 画个正方形.html":{"url":"pages/3. 绘制简单图形/3.2 画个正方形.html","title":"3.2 画个正方形","keywords":"","body":"3.2 画个正方形3.2 画个正方形 CLion项目文件位于 samples\\draw_polygon\\draw_quad\\untitled 正方形由2个三角形组成，下面的就是2个三角形的6个顶点坐标。 static const glm::vec3 kPositions[6] = { //第一个三角形 { -1.0f, -1.0f,0.0f},//左下 { 1.0f, -1.0f,0.0f},//右下 { 1.0f, 1.0f,0.0f},//右上 //第二个三角形 { 1.0f, 1.0f,0.0f},//右上 { -1.0f, -1.0f,0.0f},//左上 { -1.0f,1.0f,0.0f}//左下 }; 直接运行，却仍然是三角形。 这是因为，虽然准备了6个顶点数据，但是顶点数据是在内存中，并没有上传到GPU显存。 代码仍然是上传3个顶点，绘制一个三角形。 //void glDrawArrays(GLenum mode,GLint first,GLsizei count); glDrawArrays(GL_TRIANGLES, 0, 3);//表示从第0个顶点开始画，总共画3个顶点。 绘制2个三角形 = 绘制6个顶点，所以这里需要修改为6. glDrawArrays(GL_TRIANGLES, 0, 6);//表示从第0个顶点开始画，总共画6个顶点，即2个三角形 再次运行，成功绘制了2个三角形，组成了正方形。 但是一个三角形是黑色的！ 问题出在顶点颜色数据。 顶点从3个增加到了6个，但是顶点颜色数据仍然是3个，那么第二个三角形就没有顶点颜色可以用。 顶点颜色数据 和 顶点坐标数据 个数要一致，一一对应。 修改如下： static const glm::vec4 kColors[6] = { //第一个三角形颜色 { 1.f, 0.f, 0.f ,1.f},//左下 { 0.f, 1.f, 0.f ,1.f},//右下 { 0.f, 0.f, 1.f ,1.f},//右上 //第二个三角形颜色 { 0.f, 0.f, 1.f ,1.f},//右上 { 1.f, 0.f, 0.f ,1.f},//左上 { 1.f, 0.f, 0.f ,1.f}//左下 }; 再次运行 参考以下文章： https://huutu.blog.csdn.net/article/details/50133131 https://www.khronos.org/registry/OpenGL-Refpages/es3.0/html/glDrawArrays.xhtml https://www.khronos.org/registry/OpenGL-Refpages/es3.0/html/glEnableVertexAttribArray.xhtml Copyright © captainchen all right reserved，powered by GitbookFile Modify: 2021-04-26 14:49:02 "},"pages/3. 绘制简单图形/3.3 画个立方体.html":{"url":"pages/3. 绘制简单图形/3.3 画个立方体.html","title":"3.3 画个立方体","keywords":"","body":"3.2 画个立方体3.2 画个立方体 CLion项目文件位于 samples\\draw_polygon\\draw_cube\\untitled 立方体由6个面组成，每个面2个三角形，下面的就是6x2个三角形,共36个顶点坐标数据。 static const glm::vec3 kPositions[36] = { //Front glm::vec3(-1.0f, -1.0f, 1.0f), glm::vec3(1.0f, -1.0f, 1.0f), glm::vec3(1.0f, 1.0f, 1.0f), glm::vec3(-1.0f, -1.0f, 1.0f), glm::vec3(1.0f, 1.0f, 1.0f), glm::vec3(-1.0f, 1.0f, 1.0f), //back glm::vec3(-1.0f, -1.0f, -1.0f), glm::vec3(1.0f, -1.0f, -1.0f), glm::vec3(1.0f, 1.0f, -1.0f), glm::vec3(-1.0f, -1.0f, -1.0f), glm::vec3(1.0f, 1.0f, -1.0f), glm::vec3(-1.0f, 1.0f, -1.0f), //left glm::vec3(-1.0f, -1.0f, -1.0f), glm::vec3(-1.0f, -1.0f, 1.0f), glm::vec3(-1.0f, 1.0f, 1.0f), glm::vec3(-1.0f, -1.0f, -1.0f), glm::vec3(-1.0f, 1.0f, 1.0f), glm::vec3(-1.0f, 1.0f, -1.0f), //right glm::vec3(1.0f, -1.0f, -1.0f), glm::vec3(1.0f, -1.0f, 1.0f), glm::vec3(1.0f, 1.0f, 1.0f), glm::vec3(1.0f, -1.0f, -1.0f), glm::vec3(1.0f, 1.0f, 1.0f), glm::vec3(1.0f, 1.0f, -1.0f), //up glm::vec3(-1.0f, 1.0f, 1.0f), glm::vec3(1.0f, 1.0f, 1.0f), glm::vec3(1.0f, 1.0f, -1.0f), glm::vec3(-1.0f, 1.0f, 1.0f), glm::vec3(1.0f, 1.0f, -1.0f), glm::vec3(-1.0f, 1.0f, -1.0f), //down glm::vec3(-1.0f, -1.0f, 1.0f), glm::vec3(1.0f, -1.0f, 1.0f), glm::vec3(1.0f, -1.0f, -1.0f), glm::vec3(-1.0f, -1.0f, 1.0f), glm::vec3(1.0f, -1.0f, -1.0f), glm::vec3(-1.0f, -1.0f, -1.0f), }; 然后设置对应数量的顶点颜色。 static const glm::vec4 kColors[36] = { //Front glm::vec4(1, 0, 0, 1), glm::vec4(1, 0, 0, 1), glm::vec4(1, 0, 0, 1), glm::vec4(1, 0, 0, 1), glm::vec4(1, 0, 0, 1), glm::vec4(1, 0, 0, 1), //back glm::vec4(1, 0, 0, 1), glm::vec4(1, 0, 0, 1), glm::vec4(1, 0, 0, 1), glm::vec4(1, 0, 0, 1), glm::vec4(1, 0, 0, 1), glm::vec4(1, 0, 0, 1), //left glm::vec4(0, 1, 0, 1), glm::vec4(0, 1, 0, 1), glm::vec4(0, 1, 0, 1), glm::vec4(0, 1, 0, 1), glm::vec4(0, 1, 0, 1), glm::vec4(0, 1, 0, 1), //right glm::vec4(0, 1, 0, 1), glm::vec4(0, 1, 0, 1), glm::vec4(0, 1, 0, 1), glm::vec4(0, 1, 0, 1), glm::vec4(0, 1, 0, 1), glm::vec4(0, 1, 0, 1), //up glm::vec4(0, 0, 1, 1), glm::vec4(0, 0, 1, 1), glm::vec4(0, 0, 1, 1), glm::vec4(0, 0, 1, 1), glm::vec4(0, 0, 1, 1), glm::vec4(0, 0, 1, 1), //down glm::vec4(0, 0, 1, 1), glm::vec4(0, 0, 1, 1), glm::vec4(0, 0, 1, 1), glm::vec4(0, 0, 1, 1), glm::vec4(0, 0, 1, 1), glm::vec4(0, 0, 1, 1), }; 通知GPU绘制这36个顶点。 //void glDrawArrays(GLenum mode,GLint first,GLsizei count); glDrawArrays(GL_TRIANGLES, 0, 6*6);//表示从第0个顶点开始画，总共画6个面，每个面6个顶点。 编译运行，只看到一个正方形。 这是因为摄像机正好面对立方体的前面的中心，其他的面都被遮住了。 将原来的没有旋转的代码： glm::mat4 rotation = glm::eulerAngleYXZ(glm::radians(0.f), glm::radians(0.f), glm::radians(0.f)); //使用欧拉角旋转; 修改为： static float rotate_eulerAngle=0.f; rotate_eulerAngle+=1; glm::mat4 rotation = glm::eulerAngleYXZ(glm::radians(rotate_eulerAngle), glm::radians(rotate_eulerAngle), glm::radians(rotate_eulerAngle)); //使用欧拉角旋转; 让立方体旋转，就可以看到其他面了。 Copyright © captainchen all right reserved，powered by GitbookFile Modify: 2021-04-26 14:49:02 "},"pages/4. 着色器/4. 着色器.html":{"url":"pages/4. 着色器/4. 着色器.html","title":"4. 着色器","keywords":"","body":"4. 着色器4. 着色器 Copyright © captainchen all right reserved，powered by GitbookFile Modify: 2021-04-02 11:26:42 "},"pages/4. 着色器/4.1 着色器是什么.html":{"url":"pages/4. 着色器/4.1 着色器是什么.html","title":"4.1 着色器是什么","keywords":"","body":"4.1 着色器是什么着色器的种类4.1 着色器是什么 着色器就是Shader，Shader就是一段GPU程序源码。 我们大学就学过的C语言是CPU程序源码，Shader和C 语言有很多相似之处，也要写代码、编译、链接。 通过下面的表格来做对照。 C语言Shader 目标硬件CPUGPU 编译流程创建项目创建GPU程序 创建多个代码文件创建Shader对象(顶点Shader和片段Shader) 编写多个代码上传Shader源码到Shader对象 编译代码编译Shader 添加到链接列表添加到链接列表 链接链接 是不是很相似呢！ 渲染一个图像，其实就是在GPU上执行了Shader代码，然后将顶点坐标、颜色数据作为输入，经由Shader进行处理，然后输出像素数据到屏幕上。 和C语言不一样的是，C语言只需要一个main.c 文件就可以编译成功。 但是Shader是配套出现的， Vertex Shader(顶点着色器)、Fragment Shader(片段着色器)，两者缺一不可。 C语言Shader 目标硬件CPUGPU 代码文件列表main.cmain.vs(Vertex Shader) ...main.fs(Fragment Shader) 着色器的种类 Vertex Shader(顶点着色器)、Fragment Shader(片段着色器) 我们听到最多的就是这两个。 Geometry Shader、Computer Shader看过但是实际项目中没用过。 Tessellation Control Shader 、Tessellation Evaluation Shader这两个就几乎没有听过。 这是由工作内容决定的，大家都是从事手机游戏开发。 目前市面上的手机，很大一部分仍然是OpenGL ES3.0的版本或更低。 Computer Shader在OpenGL ES 3.1版本才开始支持。 Geometry Shader在OpenGL ES 3.2版本才开始支持。 更多资料参考OpenGL官网： https://www.khronos.org/opengl/wiki/Category:Shaders 本书也仅介绍Vertex Shader(顶点着色器)、Fragment Shader(片段着色器)。 在 3.绘制简单图形 这一章的配套项目里，ShaderSource.h 里面就存放着Vertex Shader 和 Fragment Shader 的源码。 如下图： 观察这段代码，又发现和C语言的相同之处 -- 入口都是 main 函数。 C语言Shader 目标硬件CPUGPU 入口void main()void main() 当前小节对Shader有了一个大概的映像即可，后续章节再详细介绍。 Copyright © captainchen all right reserved，powered by GitbookFile Modify: 2021-04-02 11:26:42 "},"pages/4. 着色器/4.2 Unity Shader和OpenGL Shader.html":{"url":"pages/4. 着色器/4.2 Unity Shader和OpenGL Shader.html","title":"4.2 Unity Shader和OpenGL Shader","keywords":"","body":"4.2 Unity Shader和OpenGL Shader1. Unity Shader类型2. Unity Shader代码3.Unity Shader转OpenGL Shader4.2 Unity Shader和OpenGL Shader 上一节提到，OpenGL Shader是配套出现的， Vertex Shader(顶点着色器)、Fragment Shader(片段着色器)，两者缺一不可。 但是我用了20年Unity都没有见过类似的代码，这是咋回事，Unity跳过OpenGL自己实现了图形库吗？ 1. Unity Shader类型 打开Unity，新建Shader。 在Unity中，可以创建4种Shader。 Standard Surface Shader Unlit Shader Image Effect Shader Compute Shader 这4种Shader，是对一套特定功能的Vertex Shader、Fragment Shader组合，取的名字。 以C语言为例，我们编写多个C语言代码，可以编译出各种程序，如收银台程序、聊天程序、游戏程序，每一种程序都针对特定功能。 用编写的Vertex Shader、Fragment Shader，也可以编译得到各种程序，如无光照的GPU程序、有光照的GPU程序、特效程序，每一种程序都针对特定功能。 Unity中可选的4种Shader，每一种都是针对特定功能，每一种都是由不同的Vertex Shader、Fragment Shader组成。 2. Unity Shader代码 上面说，Unity Shader是由Vertex Shader、Fragment Shader组成，那就是说，Unity Shader里面的代码由Vertex Shader、Fragment Shader拼起来咯？ 在 3.绘制简单图形 这一章的配套项目里，ShaderSource.h 就是由 Vertex Shader 和 Fragment Shader 拼起来的，那Unity Shader也是如此吗？ 创建一个 Standard Surface Shader，观察代码，发现结构完全不一样，连 入口 main 函数都没有! Shader \"Custom/NewSurfaceShader\" { Properties { _Color (\"Color\", Color) = (1,1,1,1) _MainTex (\"Albedo (RGB)\", 2D) = \"white\" {} _Glossiness (\"Smoothness\", Range(0,1)) = 0.5 _Metallic (\"Metallic\", Range(0,1)) = 0.0 } SubShader { Tags { \"RenderType\"=\"Opaque\" } LOD 200 CGPROGRAM // Physically based Standard lighting model, and enable shadows on all light types #pragma surface surf Standard fullforwardshadows // Use shader model 3.0 target, to get nicer looking lighting #pragma target 3.0 sampler2D _MainTex; struct Input { float2 uv_MainTex; }; half _Glossiness; half _Metallic; fixed4 _Color; // Add instancing support for this shader. You need to check 'Enable Instancing' on materials that use the shader. // See https://docs.unity3d.com/Manual/GPUInstancing.html for more information about instancing. // #pragma instancing_options assumeuniformscaling UNITY_INSTANCING_CBUFFER_START(Props) // put more per-instance properties here UNITY_INSTANCING_CBUFFER_END void surf (Input IN, inout SurfaceOutputStandard o) { // Albedo comes from a texture tinted by color fixed4 c = tex2D (_MainTex, IN.uv_MainTex) * _Color; o.Albedo = c.rgb; // Metallic and smoothness come from slider variables o.Metallic = _Metallic; o.Smoothness = _Glossiness; o.Alpha = c.a; } ENDCG } FallBack \"Diffuse\" } 这是因为，我们在Unity中写的Shader代码，并不是标准的OpenGL Shader，而是NVIDIA开发的Cg语言。 Cg语言可以由工具，转换成OpenGL Shader，或者DX Shader，毕竟Unity是跨平台引擎，如果没有Cg语言，那每一种功能的Shader既要写OpenGL的，又要写DX的，要累死程序员了。 3.Unity Shader转OpenGL Shader Unity中选中创建的Shader，在Inspector里，打开Shader编译平台设置，修改为 All platforms。 点击Compile and show code 将Unity Cg Shader文件转为OpenGL Shader。 转换完成后自动打开，搜索 glcore，定位到转换后的代码。 这就是转换出来的Vertex Shader代码，看到入口 main 函数了。 Copyright © captainchen all right reserved，powered by GitbookFile Modify: 2021-03-26 22:25:55 "},"pages/4. 着色器/4.3 顶点着色器.html":{"url":"pages/4. 着色器/4.3 顶点着色器.html","title":"4.3 顶点着色器","keywords":"","body":"4.3 顶点着色器1.简单的顶点着色器2.顶点着色器语法4.3 顶点着色器 顶点着色器的功能就是：对输入的顶点坐标进行处理，然后再输出。 1.简单的顶点着色器 我们来写一个简单的，实现上面所说功能的顶点着色器。 #version 330 uniform mat4 u_mvp; layout(location = 0) in vec3 a_pos; layout(location = 1) in vec4 a_color; out vec4 v_color; void main() { gl_Position = u_mvp * vec4(a_pos, 1.0); v_color = a_color; }; 这个简单的着色器，将输入的vec3的顶点坐标，转换为vec4后输出。 2.顶点着色器语法 2.1 版本限定 #version 330 第一行表示当前Shader，需要的GLSL(OpenGL着色器语言)最低版本。 如果你的电脑，支持的OpenGL，达不到Shader要求的，那么这个Shader就无效。 不过一般在检测软件上只能看到OpenGL版本，看不到GLSL版本，这里提供对应关系表格。 OpenGL VersionGLSL Version 2.01.10 2.11.20 3.01.30 3.11.40 3.21.50 >3.3=OpenGL Version 根据表格，第一行的 330 对应OpenGL 3.3，电脑上至少需要支持OpenGL 3.3才可以正常运行。 2.2 统一变量 uniform mat4 u_mvp; uniform 用来修饰统一变量。 GPU是并行的，Shader是执行在GPU上的程序。 当我们需要绘制3个顶点，GPU将3个顶点数据，分摊到3个GPU逻辑单元并行处理，每个逻辑单元处理的不同的顶点坐标数据，称之为属性变量。 每个逻辑单元也会需要一些相同的数据，这些相同的数据，称之为统一变量。 2.3 属性变量 layout(location = 0) in vec3 a_pos; layout(location = 1) in vec4 a_color; 属性变量，上面已经介绍了。 vec3 vPos 表示定义了 vec3 的变量 vPos。 in 表示这个变量，每执行一次Shader，都需要被赋值。 layout(location = 0) 表示变量的序号是0。 2.4 输出变量 out vec4 v_color; 输出变量由out关键字修饰，用于从顶点着色器，传递数据到片段着色器。 2.5 函数逻辑 void main() { gl_Position = vec4(vPos, 1.0); } 每个Shader都有入口函数 main()，顶点Shader主要工作就是：计算坐标。 得到坐标计算结果后，传给内置变量 gl_Position。 GPU拿到gl_Position，执行裁剪。 参考文档： Vertex Shader: https://www.khronos.org/opengl/wiki/Vertex_Shader#Inputs OPENGL ES 3.0编程指南 第5章 OpenGL ES 着色语言 Copyright © captainchen all right reserved，powered by GitbookFile Modify: 2021-04-02 11:26:42 "},"pages/4. 着色器/4.4 片段着色器.html":{"url":"pages/4. 着色器/4.4 片段着色器.html","title":"4.4 片段着色器","keywords":"","body":"4.4 片段着色器1.简单的片段着色器2.片段着色器语法3. 插值4.4 片段着色器 片段着色器的功能就是：输出颜色。 在上一节(顶点着色器)里介绍了，顶点着色器是并行的，当我们需要绘制3个顶点，GPU将3个顶点数据，分摊到3个GPU逻辑单元并行处理，每个GPU逻辑单元同时执行顶点着色器程序。 片段着色器也是并行的，不过执行的次数不是顶点个数，而是屏幕像素个数。 举例绘制一个960x540的长方形，每一个像素点的颜色，都是通过执行一次片段着色器来得到，那么GPU需要执行960x540次。 顶点数越多，顶点着色器执行次数越多。 屏幕分辨率越高，片段着色器执行次数越多。 这里可以推出手游常见的两种优化方式：减少顶点、降低分辨率。 1.简单的片段着色器 #version 330 in vec4 v_color; layout(location = 0) out vec4 o_fragColor; void main() { o_fragColor = v_color; } 这就是第3章用的片段着色器，仅实现了片段着色器的最基础功能。 2.片段着色器语法 2.1 版本限定 #version 330 在顶点着色器里讲了，这里就不重复了。 2.2 输入变量 in vec4 v_color; 顶点着色器的输出变量，传递到片段着色器的输入变量。 2.3 输出变量 layout(location = 0) out vec4 o_fragColor; 片段着色器的功能，就是计算颜色，然后输出给显卡。 片段着色器有一个或多个输出变量，以out 修饰，这里就是 o_fragColor。 片段着色器可以由多个输出变量，输出到多个渲染目标(MRT)。 例如在Unity UI上显示模型时，可以将模型渲染到RTT，此时RTT就是片段着色器的渲染目标。 2.4 函数逻辑 void main() { o_fragColor = v_color; } 入口函数 main()，上面代码就是将片段着色器输出的颜色，直接输出。 3. 插值 顶点着色器输出颜色，作为片段着色器输入颜色。 这句话是对的，但是，顶点着色器输出颜色 ≠ 片段着色器输入颜色。 仔细思考，顶点着色器对每个顶点执行一次，片段着色器对每个像素执行一次，这两个着色器的目标都不一样。 在 3.2 画个正方形 这一节，绘制一个200x200 左右大小的正方形。(如上图) 正方形四个顶点，顶点着色器只需要执行4次，而面对200x200个像素，片段着色器，需要执行200x200次。 只有正方形四个顶点的那四个像素，才能直接从顶点着色器拿到颜色数据，那中间的像素颜色数据从哪里来？ 插值 中间的像素颜色，都是插值得到的。 左上角顶点颜色是红色，右上角顶点颜色是蓝色，可以看到中间颜色是由红色、蓝色插值混合而成。 注意：所有从顶点着色器输出到片段着色器的数据，都会插值！ Copyright © captainchen all right reserved，powered by GitbookFile Modify: 2021-04-02 16:46:13 "},"pages/5. 绘制贴图/5. 绘制贴图.html":{"url":"pages/5. 绘制贴图/5. 绘制贴图.html","title":"5. 绘制贴图","keywords":"","body":"5. 绘制贴图5. 绘制贴图 没有颜色的世界是枯燥的，想用心去欣赏，却没有太多细节。 就例如下面的模型，看起来是一个鱼缸，仅此而已。 给模型添加上贴图，鱼缸就有了生机。 Copyright © captainchen all right reserved，powered by GitbookFile Modify: 2021-04-02 15:35:30 "},"pages/5. 绘制贴图/5.1 颜色和贴图.html":{"url":"pages/5. 绘制贴图/5.1 颜色和贴图.html","title":"5.1 颜色和贴图","keywords":"","body":"5.1 颜色和贴图1.顶点色显示逻辑2.贴图显示逻辑5.1 颜色和贴图 在第3章-绘制简单图形里，分别绘制了彩色的三角形、四边形、立方体，这些多边形的颜色，来自于代码中指定的顶点颜色。 那既然可以指定顶点颜色，那我在代码中指定所有顶点颜色，不就可以绘制彩色模型，为什么还需要贴图呢？ 1.顶点色显示逻辑 在 4.4 片段着色器中提到，顶点颜色从顶点着色器输出，然后输入到片段着色器，是经过插值的。 上图是 3.2 画个正方形 的实例，左上角颜色是红色，右上角颜色是蓝色，可以看到中间颜色是由红色、蓝色插值混合而成。 那顶点色插值能做到下图的效果吗？ 明显是做不到的。 2.贴图显示逻辑 顶点色能做到的效果有限，所以有另一套机制:UV坐标。 UV坐标指的是顶点对应在图片的哪个位置，仍旧拿上面的效果举例，4个顶点(左下、右下、右上、左上)分别和图片的4个角对应，那么UV坐标就是下面这样: static const glm::vec3 Positions[6] = { //第一个三角形 { -1.0f, -1.0f,0.0f},//左下 { 1.0f, -1.0f,0.0f},//右下 { 1.0f, 1.0f,0.0f},//右上 //第二个三角形 { 1.0f, 1.0f,0.0f},//右上 { -1.0f, -1.0f,0.0f},//左上 { -1.0f,1.0f,0.0f}//左下 }; static const glm::vec2 UVs[6] = { //第一个三角形 { -1.0f, -1.0f},//左下 { 1.0f, -1.0f},//右下 { 1.0f, 1.0f},//右上 //第二个三角形 { 1.0f, 1.0f},//右上 { -1.0f, -1.0f},//左上 { -1.0f, 1.0f}//左下 } 相信你也看出来了，UV坐标范围是[0,1]。 上面这种顶点坐标和图片对应起来的操作，一般叫做UV映射。 想象一下贴手机膜，就是这种操作，贴上去，不然怎么叫贴图。 Copyright © captainchen all right reserved，powered by GitbookFile Modify: 2021-04-04 15:28:32 "},"pages/5. 绘制贴图/5.2 贴图文件介绍.html":{"url":"pages/5. 绘制贴图/5.2 贴图文件介绍.html","title":"5.2 贴图文件介绍","keywords":"","body":"5.2 贴图文件介绍1.没有压缩的图片格式2. CPU压缩的图片格式3. 显卡支持的图片格式5.2 贴图文件介绍 贴图文件按格式大致分为3种： 没有压缩的图片格式 CPU压缩的图片格式 显卡支持的图片格式 下面一一介绍。 1.没有压缩的图片格式 在Unity中设置图片格式时，选择TrueColor就是没有压缩的图片格式，即真彩色。 没有压缩的TrueColor，每个像素值RGB分别用1个字节来表示，那么一张1024x1024的图，就是 1024x 1024x3=3145728，就是3M。 在Windows系统中，不压缩的图片格式就是 .bmp，下面用画图软件创建1024x1024的图片，保存为.bmp格式。 查看图片大小。 发现图片大小是 3145782。 这比上面计算的TrueColor图片尺寸大了一些，多了 54 字节。 这是为什么？ 1.1 文件的身份证--文件头 计算机文件类型数以千计，当用软件打开一个文件时，是如何判断这个文件可打开呢？ 其实每一种文件，都有自己的身份证--文件头。 文件头就是文件的头部区域，所谓文件就是硬盘中存储的一块字节数据，这块字节数据的前面几个字节，就是文件头。 一个文件，一般是由2部分组成： 文件头实际数据 上面创建的 .bmp 图片，就是因为多了文件头，所以会比计算的TrueColor尺寸大。 用HxD十六进制编辑器打开图片。 下载地址：https://mh-nexus.de/en/downloads.php?product=HxD20 可以看到大片都是24 1C ED，这是因为图片里的红色RGB为(237,28,36)。 文件开始有54个字节，就是.bmp图片格式的文件头。 当我们用软件打开图片文件，软件会先读取前54个字节，判断是.bmp格式，就直接读取后面的字节数据，然后显示出来。 2. CPU压缩的图片格式 在日常工作中，几乎不会用到.bmp格式，因为占用空间太大了，存储/传输都不方便。 对于大文件，我们一般会用文件压缩软件对其进行压缩，保存为.zip等格式。 文件压缩方式分为无损压缩和有损压缩。 源文件压缩之后，再解压得到的文件，和源文件一致，这就叫做无损压缩。 我们熟知的.zip .rar .7z都是无损压缩，毕竟数据完整性是硬性需求。 那么什么时候能用到有损压缩？ 对于精度要求不是那么高的，就可以用有损压缩，例如图片、骨骼动画。 2.1 无损压缩 .png是常见的无损压缩格式。 把上面创建的无标题.bmp存为.png格式，文件大小变为 6,410 字节。 拖到 HxD十六进制编辑器中。 前面一段是文件头。 随后就是被压缩的颜色数据。 最后是文件尾。 2.1 有损压缩 用的较多的有损压缩是 .jpg。 jpg图片可以一直压缩，直到压不动了为止。 3. 显卡支持的图片格式 3.1 显卡图片格式优势 我们编写代码，读取.png、.jpg图片文件用于渲染，流程如下： startgame=>start: 启动游戏 load_image_to_memory=>start: 加载图片到内存 uncompress_image_to_RGB=>inputoutput: 解压png/jpg得到RGB数据 upload_RGB_to_GPU=>inputoutput: 上传RGB数据到GPU render=>end: 渲染 startgame->load_image_to_memory->uncompress_image_to_RGB->upload_RGB_to_GPU->render 解压是特别耗时的操作，并且在解压的时候，需要占用额外一份内存。 因此一般我们都会选择将.png、.jpg图片，预先转换为显卡支持的图片格式，打包到游戏安装包，这样进游戏就只需要加载到内存，然后上传到GPU即可。 startgame=>start: 启动游戏 load_image_to_memory=>inputoutput: 加载GPU支持的图像格式文件到内存 upload_RGB_to_GPU=>inputoutput: 上传图像数据到GPU render=>end: 渲染 startgame->load_image_to_memory->upload_RGB_to_GPU->render 3.2 Unity中的图片压缩 用Unity导入一个项目往往需要花费特别长的时间，有很大一部分都是花费在,预先转换图片为显卡支持的图像格式。 .png、.jpg图片文件读取到内存，然后解压，转换格式，存放到Library目录。 游戏Play时，从Library读取转换好的图像数据。 因为每个系统、每一种GPU，支持的最优图像格式都不同，所以根据选择的Platform，Unity会转换为不同的图像格式。 3.3 常用显卡支持图像格式 在Unity的Texture Import Setting可以看到常用的显卡支持图像格式。 带 Compressed的都是压缩格式，由于显卡的大规模并行处理特性，解压缩不再是问题了。 Copyright © captainchen all right reserved，powered by GitbookFile Modify: 2021-04-16 22:07:21 "},"pages/5. 绘制贴图/5.3 CPU与GPU的通信方式.html":{"url":"pages/5. 绘制贴图/5.3 CPU与GPU的通信方式.html","title":"5.3 CPU与GPU的通信方式","keywords":"","body":"5.3 CPU与GPU的通信方式5.3 CPU与GPU的通信方式 在上一节了解到常用的.png图片，需要解压得到RGB数据，并且上传到GPU中。注意这里用上传这个词，而不是复制，这是由CPU和显卡的通信方式决定的。 CPU与GPU的通信方式 CPU和GPU是一种CS模式，即客户端-服务器模式。 客户端不能直接访问服务器资源，客户端想对服务器资源进行操作，只能通过网络协议交互，由服务器进行操作。 CPU就是客户端，GPU就是服务器。 上传图片数据到显卡分为几步： 步骤OpenGL API描述 1glGenTextures通知显卡创建纹理对象，返回句柄; 2glBindTexture将纹理绑定到特定纹理目标; 3glTexImage2D将图片rgb数据上传到GPU; 需要注意的是，上面的API都是阻塞式的。 所以在游戏中，需要减小图片尺寸减少上传时间，需要打包图集减少上传次数。 不止图片RGB数据需要上传，在第3章-绘制简单图形中，我们将顶点坐标和颜色，也上传到GPU中。 Copyright © captainchen all right reserved，powered by GitbookFile Modify: 2021-04-12 19:57:32 "},"pages/5. 绘制贴图/5.4 使用stb_image解析图片.html":{"url":"pages/5. 绘制贴图/5.4 使用stb_image解析图片.html","title":"5.4 使用stb_image解析图片","keywords":"","body":"5.4 使用stb_image解析图片1. 开源的图片解析库2. 导入stb库3. 加载图片并解析4. 解析结果验证5.4 使用stb_image解析图片 CLion项目文件位于 samples\\texture\\load_image 前面介绍了.png、.jpg图片文件想要用于渲染，首先得加载到内存，然后解压得到RGB数据，然后才能将RGB数据上传到GPU用于渲染。 这一节来实现图片文件加载与解压。 1. 开源的图片解析库 目前各大游戏引擎常用的图片解析库是 FreeImage，支持几乎所有的图片格式，官网地址： https://freeimage.sourceforge.io/index.html 支持图片格式多，意味着代码量大，我们暂时只需要加载 .png、.jpg，找个轻量的库就可以了。 一个绝佳的选择就是 stb_image。 std是一个单头文件开源库，每个头文件实现一种功能，官网：https://github.com/nothings/stb 2. 导入stb库 下载stb源代码，放到项目的depends目录下。 这样就可以在项目中使用了。 3. 加载图片并解析 创建类Texture2D，管理图片相关接口。 在使用 stb_image 解析图片文件之前，先添加相关宏定义： #define STB_IMAGE_IMPLEMENTATION 再导入头文件： #include \"stb/stb_image.h\" 然后编写接口代码，加载图片文件: Texture2D* Texture2D::LoadFromFile(std::string& image_file_path) { Texture2D* texture2d=new Texture2D(); stbi_set_flip_vertically_on_load(true);//翻转图片，解析出来的图片数据从左下角开始，这是因为OpenGL的纹理坐标起始点为左下角。 int channels_in_file;//通道数 unsigned char* data = stbi_load(image_file_path.c_str(), &(texture2d->width_), &(texture2d->height_), &channels_in_file, 0); if (data!= nullptr) { //根据颜色通道数，判断颜色格式。 switch (channels_in_file) { case 1: { texture2d->gl_texture_format_ = GL_ALPHA; break; } case 3: { texture2d->gl_texture_format_ = GL_RGB; break; } case 4: { texture2d->gl_texture_format_ = GL_RGBA; break; } } } //释放图片文件内存 stbi_image_free(data); return texture2d; } 然后在main.cpp 中调用接口。 //创建Texture void CreateTexture(std::string image_file_path) { Texture2D* texture2d=Texture2D::LoadFromFile(image_file_path); } int main(void) { init_opengl(); CreateTexture(\"../data/images/red.png\"); compile_shader(); ...... } 4. 解析结果验证 调用stbi_load解析图片成功后，返回图像RGB数据(data)、宽、高、通道数。 查看data内存，如下图： 可以看到都是重复的 ed 1c 24 ff，转换到十进制就是237 28 36 255，这正是上一节创建的红色图片的像素颜色值。 这说明已经成功解析了.png格式图片，获取到了原始的RGB数据，下一步就可以上传到GPU中进行渲染。 Copyright © captainchen all right reserved，powered by GitbookFile Modify: 2021-04-12 19:58:15 "},"pages/5. 绘制贴图/5.5 绘制带贴图的立方体盒子.html":{"url":"pages/5. 绘制贴图/5.5 绘制带贴图的立方体盒子.html","title":"5.5 绘制带贴图的立方体盒子","keywords":"","body":"5.5 绘制带贴图的立方体盒子1. 上传RGB数据到显卡2. Shader中使用纹理3. 上传UV坐标5.指定纹理渲染5.5 绘制带贴图的立方体盒子 CLion项目文件位于 samples\\texture\\draw_cube_texture 上一节已经解析了图片，得到RGB数据，这一节将数据上传到显卡并渲染。 1. 上传RGB数据到显卡 在 texture2d.h 中，添加成员变量gl_texture_id_存储GPU创建纹理的唯一ID。 GLuint gl_texture_id_;//纹理ID 解析图片成功后，将图片RGB数据上传到GPU。 Texture2D* Texture2D::LoadFromFile(std::string& image_file_path) { Texture2D* texture2d=new Texture2D(); stbi_set_flip_vertically_on_load(true);//翻转图片，解析出来的图片数据从左下角开始，这是因为OpenGL的纹理坐标起始点为左下角。 int channels_in_file;//通道数 unsigned char* data = stbi_load(image_file_path.c_str(), &(texture2d->width_), &(texture2d->height_), &channels_in_file, 0); if (data!= nullptr) { //根据颜色通道数，判断颜色格式。 ...... } //1. 通知显卡创建纹理对象，返回句柄; glGenTextures(1, &(texture2d->gl_texture_id_)); //2. 将纹理绑定到特定纹理目标; glBindTexture(GL_TEXTURE_2D, texture2d->gl_texture_id_); //3. 将图片rgb数据上传到GPU; glTexImage2D(GL_TEXTURE_2D, 0, GL_RGB, texture2d->width_, texture2d->height_, 0, texture2d->gl_texture_format_, GL_UNSIGNED_BYTE, data); //4. 指定放大，缩小滤波方式，线性滤波，即放大缩小的插值方式; glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR); //释放图片文件内存 stbi_image_free(data); return texture2d; } 这样，RGB数据就上传到显卡中了。 数据上传后，返回纹理句柄供后续使用。 下面来看看在Shader中如何从纹理上获取颜色数据。 2. Shader中使用纹理 在片段Shader中使用，GLSL提供函数 texture ，在纹理的指定坐标上，取出颜色值。 gvec4 texture(gsampler{2,3}D sampler, vec{2,3} P [, float bias]); 参数sampler就是纹理数据。 参数p就是UV坐标。 下面就是完整的片段Shader。 #version 330 uniform sampler2D u_diffuse_texture; in vec4 v_color; in vec2 v_uv; layout(location = 0) out vec4 o_fragColor; void main() { o_fragColor = texture(u_diffuse_texture,v_uv); }; 主要是调用texture函数，从纹理 u_diffuse_texture 中，以 v_uv 为UV坐标，取出颜色值，赋值给 o_fragColor作为颜色输出。 UV坐标，在 5.1 颜色和贴图 这一节简单介绍过，注意看上面的片段Shader代码： in vec2 v_uv; 变量v_uv被 in 修饰，说明UV坐标是从顶点Shader传递过来的，数据经过插值。 顶点Shader代码如下： #version 330 uniform mat4 u_mvp; layout(location = 0) in vec3 a_pos; layout(location = 1) in vec4 a_color; layout(location = 2) in vec2 a_uv; out vec4 v_color; out vec2 v_uv; void main() { gl_Position = u_mvp * vec4(a_pos, 1.0); v_color = a_color; v_uv = a_uv; }; 介绍完了纹理的使用过程，下面就传入UV坐标和纹理到Shader中进行渲染。 3. 上传UV坐标 UV坐标和顶点坐标也是一一对应，且取值范围是[0,1]。 立方体有6个面，每个面2个三角形，对应UV坐标数据如下： static const glm::vec2 kUvs[36] = { //Front glm::vec2(0.0f, 0.0f), glm::vec2(1.0f, 0.0f), glm::vec2(1.0f, 1.0f), glm::vec2(0.0f, 0.0f), glm::vec2(1.0f, 1.0f), glm::vec2(0.0f, 1.0f), //back glm::vec2(0.0f, 0.0f), glm::vec2(1.0f, 0.0f), glm::vec2(1.0f, 1.0f), glm::vec2(0.0f, 0.0f), glm::vec2(1.0f, 1.0f), glm::vec2(0.0f, 1.0f), //left glm::vec2(0.0f, 0.0f), glm::vec2(1.0f, 0.0f), glm::vec2(1.0f, 1.0f), glm::vec2(0.0f, 0.0f), glm::vec2(1.0f, 1.0f), glm::vec2(0.0f, 1.0f), //right glm::vec2(0.0f, 0.0f), glm::vec2(1.0f, 0.0f), glm::vec2(1.0f, 1.0f), glm::vec2(0.0f, 0.0f), glm::vec2(1.0f, 1.0f), glm::vec2(0.0f, 1.0f), //up glm::vec2(0.0f, 0.0f), glm::vec2(1.0f, 0.0f), glm::vec2(1.0f, 1.0f), glm::vec2(0.0f, 0.0f), glm::vec2(1.0f, 1.0f), glm::vec2(0.0f, 1.0f), //down glm::vec2(0.0f, 0.0f), glm::vec2(1.0f, 0.0f), glm::vec2(1.0f, 1.0f), glm::vec2(0.0f, 0.0f), glm::vec2(1.0f, 1.0f), glm::vec2(0.0f, 1.0f), }; 然后获取顶点Shader中的UV变量： a_uv_location = glGetAttribLocation(program, \"a_uv\"); 启用顶点Shader属性(a_uv)： glEnableVertexAttribArray(a_uv_location); 联顶点UV数据： //关联顶点UV数据 glVertexAttribPointer(a_uv_location, 2, GL_FLOAT, false, sizeof(glm::vec2), kUvs); 5.指定纹理渲染 上面已经上传了图片RGB到GPU中，并且声称了纹理，拿到了纹理句柄。但是仍然需要将纹理句柄传入到Shader，下面就来做这个事情。 //指定GPU程序(就是指定顶点着色器、片段着色器) glUseProgram(program); ...... //贴图设置 //激活纹理单元0 glActiveTexture(GL_TEXTURE0); //将加载的图片纹理句柄，绑定到纹理单元0的Texture2D上。 glBindTexture(GL_TEXTURE_2D,texture2d->gl_texture_id_); //设置Shader程序从纹理单元0读取颜色数据 glUniform1i(u_diffuse_texture_location,GL_TEXTURE0); //void glDrawArrays(GLenum mode,GLint first,GLsizei count); glDrawArrays(GL_TRIANGLES, 0, 6*6);//表示从第0个顶点开始画，总共画6个面，每个面6个顶点。 glUseProgram(-1); 代码很简单，不过逻辑很绕，这里需要解释一下。 我们并不直接将纹理句柄指定给片段Shader，而是通过纹理单元进行中转。 纹理单元可以看做是纹理句柄的容器。 首先激活纹理单元，然后将纹理句柄绑定到纹理单元，然后将纹理单元指定给片段Shader。 最终运行效果： Copyright © captainchen all right reserved，powered by GitbookFile Modify: 2021-04-26 14:49:02 "},"pages/5. 绘制贴图/5.6 压缩纹理.html":{"url":"pages/5. 绘制贴图/5.6 压缩纹理.html","title":"5.6 压缩纹理","keywords":"","body":"5.6 压缩纹理1. 为什么使用压缩纹理？2. 使用压缩纹理3. 查看压缩纹理效果4. 问题与优化5.6 压缩纹理 CLion项目文件位于 samples\\texture\\draw_cube_texture_compress 上一节解析了 urban.jpg 这个图片，从中拿到RGB数据，上传到GPU，进行渲染。 上传RGB数据到GPU，使用了下面的代码： //3. 将图片rgb数据上传到GPU; glTexImage2D(GL_TEXTURE_2D, 0, GL_RGB, texture2d->width_, texture2d->height_, 0, texture2d->gl_texture_format_, GL_UNSIGNED_BYTE, data); 接口定义如下： /** * @brief 将图片数据上传到GPU; * @param target 目标纹理，GL_TEXTURE_2D(2D纹理) * @param level 当图片数据是包含多个mipmap层级时，指定使用mipmap层级。 * @param internalformat 图片数据上传到GPU后，在显存中保存为哪种格式？ * @param width * @param height * @param border * @param format 上传的图片数据格式，RGB、RGBA、Alpha等 * @param type 图片数据变量格式，一般都是GL_UNSIGNED_BYTE(0-255范围) * @param pixels 图片数据 * @return */ void glTexImage2D(GLenum target, GLint level, GLint internalformat, GLsizei width, GLsizei height, GLint border, GLenum format, GLenum type, const void * pixels); 注意 internalformat 这个参数。 图片数据上传到到GPU后，可以选择保存的格式。 而我们这一章的主题是压缩纹理，那么我要讲的就是，可以保存为压缩格式。 1. 为什么使用压缩纹理？ 为什么图片导入Unity之后，默认会设置为压缩格式？ 在glTexImage2D这个接口里面，设置图片数据保存为压缩格式后，会有什么好处？ 答案就是：节省显存。 如今的3A大作，各种4K贴图、超高精度模型，一个场景数据量几G，这些数据都是要上传到显存的，为了让游戏适配更多的硬件，开发者们也是各显神通，压缩纹理就是OpenGL官方提供的一种手段。 2. 使用压缩纹理 OpenGL支持的纹理数据格式如下： 纹理格式压缩纹理格式 GL_ALPHAGL_COMPRESSED_ALPHA GL_LUMINANCEGL_COMPRESSED_LUMINANCE GL_LUMINANCE_ALPHAGL_COMPRESSED_LUMINANCE_ALPHA GL_RGBGL_COMPRESSED_RGB GL_RGBAGL_COMPRESSED_RGBA GL_INTENSITYGL_COMPRESSED_INTENSITY 之前glTexImage2D这个接口的 internalformat 参数值是GL_RGB，现在只要设置为对应的压缩纹理格式GL_COMPRESSED_RGB即可。 //3. 将图片rgb数据上传到GPU;并进行压缩。 glTexImage2D(GL_TEXTURE_2D, 0, GL_COMPRESSED_RGB, texture2d->width_, texture2d->height_, 0, texture2d->gl_texture_format_, GL_UNSIGNED_BYTE, data); 3. 查看压缩纹理效果 代码编译运行后，正常绘制了立方体，但是怎么样确认压缩纹理的效果呢，就是说怎么样确认显存占用降低？ 这里借助GPU状态工具 - GPU-Z 来查看实时显存。 使用未压缩纹理，glTexImage2D接口调用前后显存对比如下： 从52m 变动到 116m，使用了约 64m 显存。 使用压缩纹理，接口调用前后显存对比如下： 从52m 变动到 60m，使用了约 8m 显存。 效果很明显，压缩纹理后，占用的显存是原来的 1/6 左右。 对比Unity中压缩后的效果，差异不大。 4. 问题与优化 启动时有一段时间的白屏，断点调试发现stbi_load 和 glTexImage2D耗时较长，这里引入stopwatch工具类来进行测量。 Texture2D* Texture2D::LoadFromFile(std::string& image_file_path) { ...... StopWatch stopwatch; stopwatch.start(); unsigned char* data = stbi_load(image_file_path.c_str(), &(texture2d->width_), &(texture2d->height_), &channels_in_file, 0); stopwatch.stop(); std::int64_t decompress_jpg_cost = stopwatch.milliseconds(); ...... stopwatch.restart(); //3. 将图片rgb数据上传到GPU;并进行压缩。 glTexImage2D(GL_TEXTURE_2D, 0, GL_COMPRESSED_RGB, texture2d->width_, texture2d->height_, 0, texture2d->gl_texture_format_, GL_UNSIGNED_BYTE, data); stopwatch.stop(); std::int64_t upload_and_compress_cost = stopwatch.milliseconds(); ...... } 耗时结果如下： 从硬盘加载jpg并解析得到RGB数据：1571 ms 上传RGB数据到GPU并压缩：960 ms 这只是一张4096的图片，就花费了2.5s的时间，我们必须想办法优化。 制定优化方案之前，先理清楚为什么这么慢，主要是3个原因： 解析jpg慢：jpg是一种压缩图片文件，需要解压才可以得到未压缩的RGB数据，解压是很慢的一个过程。 上传慢：4096的图片，未压缩的RGB数据大小是48MB，上传要耗费一定时间。 压缩慢：数据上传后，GPU对RGB数据进行压缩存储，压缩需要耗费时间。 对应的解决办法就是：使用GPU支持的压缩纹理数据格式。 具体做法就是：将GPU中压缩好的纹理数据，保存到硬盘作为图片文件。 带来的好处是： 无需解析，直接上传GPU。 数据已经压缩，上传数据量小。 数据已经压缩，上传之后无需再次压缩。 OpenGL提供了接口glGetCompressedTexImage，将GPU中压缩好的纹理数据，从显存下载到内存，下一节将制作一个工具，对.jpg、.png 图片进行批量处理。 Copyright © captainchen all right reserved，powered by GitbookFile Modify: 2021-04-19 11:27:54 "},"pages/5. 绘制贴图/5.7 图片压缩工具.html":{"url":"pages/5. 绘制贴图/5.7 图片压缩工具.html","title":"5.7 图片压缩工具","keywords":"","body":"5.7 图片压缩工具1. 从GPU下载压缩好的纹理数据2. 将纹理数据保存为文件3. 添加文件头5.7 图片压缩工具 CLion项目文件位于 samples\\texture\\export_compressed_texture 上一节了解了压缩纹理的优势 以及需要进行优化的点，这一节就来实现优化所需的图片压缩工具。 GPU将上传的RGB数据进行压缩保存之后，我们可以借助OpenGL提供的接口glGetCompressedTexImage，将GPU中压缩好的纹理数据，从显存下载到内存，下面就来实践。 1. 从GPU下载压缩好的纹理数据 在texture2d.cpp添加函数 CompressImageFile ，代码如下： void Texture2D::CompressImageFile(std::string& image_file_path,std::string& save_image_file_path) { Texture2D* texture2d=LoadFromFile(image_file_path); //1. 获取压缩是否成功 GLint compress_success=0; glGetTexLevelParameteriv(GL_TEXTURE_2D, 0, GL_TEXTURE_COMPRESSED, &compress_success); //2. 获取压缩好的纹理数据尺寸 GLint compress_size=0; glGetTexLevelParameteriv(GL_TEXTURE_2D, 0, GL_TEXTURE_COMPRESSED_IMAGE_SIZE, &compress_size); //3. 获取具体的纹理压缩格式 GLint compress_format=0; glGetTexLevelParameteriv(GL_TEXTURE_2D, 0, GL_TEXTURE_INTERNAL_FORMAT, &compress_format); //4. 从GPU中，将显存中保存的压缩好的纹理数据，下载到内存 void* img=malloc(compress_size); glGetCompressedTexImage(GL_TEXTURE_2D,0,img); } 相关接口定义如下： /** * @brief 获取指定mipmap层级纹理的相关信息; * @param target 目标纹理，GL_TEXTURE_2D(2D纹理) * @param level 当图片数据是包含多个mipmap层级时，指定使用mipmap层级。 * @param pname 想获得什么信息？GL_TEXTURE_COMPRESSED(纹理压缩是否成功) GL_TEXTURE_COMPRESSED_IMAGE_SIZE(纹理压缩后的大小) GL_TEXTURE_INTERNAL_FORMAT(纹理压缩后的格式) * @param params 用来接收查询结果的指针 * @return */ void glGetTexLevelParameteriv(GLenum target, GLint level, GLenum pname, GLint * params); /** * @brief 下载指定mipmap层级压缩纹理数据; * @param target 目标纹理，GL_TEXTURE_2D(2D纹理) * @param level 当图片数据是包含多个mipmap层级时，指定使用mipmap层级。 * @param img 用来保存纹理数据的内存块指针 * @return */ void glGetCompressedTexImage(GLenum target, GLint level, void * img); 然后在main函数中进行调用。 int main(void) { init_opengl(); //从GPU中，将显存中保存的压缩好的纹理数据，下载到内存，并保存到硬盘。 std::string src_image_file_path(\"../data/images/urban.jpg\"); std::string cpt_file_path(\"../data/images/urban.cpt\"); Texture2D::CompressImageFile(src_image_file_path,cpt_file_path); ...... } 运行项目测试，断点查看，数据已经从GPU下载到内存中，数据大小为8388608字节。 2. 将纹理数据保存为文件 上面只是将GPU中压缩好的纹理数据，从显存下载到内存，现在来进行最后一步，保存为文件。 在函数 CompressImageFile 添加保存文件的代码。 void Texture2D::CompressImageFile(std::string& image_file_path,std::string& save_image_file_path) { .... //4. 保存为文件 ofstream output_file_stream(save_image_file_path,ios::out | ios::binary); output_file_stream.write((char*)img,compress_size); output_file_stream.close(); } 运行项目，可以看到纹理数据被保存到文件 urban.cpt 中。 cpt 是我取自`compressed texture`的缩写。 3. 添加文件头 压缩纹理数据已经从GPU下载到内存，并保存为.cpt文件，但是文件仍然不是完全体，还需要进化。 在调用OpenGL提供的接口，上传图片数据到GPU时，除了需要传入图片数据，还需要传入图片mipmap层级、宽、高、压缩纹理格式等信息，现在.cpt 文件里面只有图片数据，所以还需要将其他的参数写入到.cpt 文件。 因为这些数据要在读取.cpt文件最开始的时候读取，所以将其作为文件头写入。 可以用一个文件头结构体来组织这些信息，在 texture2d.h 定义结构体TpcFileHead: //tcp文件头 struct TpcFileHead { char type_[3]; int mipmap_level_; int width_; int height_; int gl_texture_format_; int compress_size_; }; 在函数 CompressImageFile 添加写入文件头的代码。 void Texture2D::CompressImageFile(std::string& image_file_path,std::string& save_image_file_path) { .... //5. 保存为文件 ofstream output_file_stream(save_image_file_path,ios::out | ios::binary); TpcFileHead tcp_file_head; tcp_file_head.type_[0]='c'; tcp_file_head.type_[1]='p'; tcp_file_head.type_[2]='t'; tcp_file_head.mipmap_level_=texture2d->mipmap_level_; tcp_file_head.width_=texture2d->width_; tcp_file_head.height_=texture2d->height_; tcp_file_head.gl_texture_format_=compress_format; tcp_file_head.compress_size_=compress_size; output_file_stream.write((char*)&tcp_file_head,sizeof(TpcFileHead)); output_file_stream.write((char*)img,compress_size); output_file_stream.close(); } 再次运行项目测试，并用十六进制编辑器打开urban.cpt文件，查看文件头是否正常写入。 下一步，就可以直接加载urban.cpt文件进行渲染。 Copyright © captainchen all right reserved，powered by GitbookFile Modify: 2021-04-20 10:37:38 "},"pages/5. 绘制贴图/5.8 使用压缩纹理.html":{"url":"pages/5. 绘制贴图/5.8 使用压缩纹理.html","title":"5.8 使用压缩纹理","keywords":"","body":"5.8 使用压缩纹理1. 加载cpt文件2. 上传cpt压缩纹理数据并渲染3. 性能提升对比5.8 使用压缩纹理 CLion项目文件位于 samples\\texture\\draw_cube_compress_texture 前面了解了压缩纹理的优势，以及制作了纹理压缩的工具，这一节就加载 压缩纹理文件 urban.cpt进行渲染。 1. 加载cpt文件 之前项目中使用的是.jpg图片，.jpg图片并不是GPU支持的格式，需要借助stb_image这个库，在CPU中进行解析得到RGB数据，再上传到GPU。 本节要使用的.cpt文件，数据是从GPU下载保存的，是GPU支持的格式，所以就不需要再使用stb_image了，原来的加载流程也需要修改。 修改Texture2D::LoadFromFile，使用 C++ 标准库读取.cpt文件： Texture2D* Texture2D::LoadFromFile(std::string& image_file_path) { Texture2D* texture2d=new Texture2D(); StopWatch stopwatch; stopwatch.start(); //读取 cpt 压缩纹理文件 ifstream input_file_stream(image_file_path,ios::in | ios::binary); TpcFileHead tcp_file_head; input_file_stream.read((char*)&tcp_file_head,sizeof(TpcFileHead)); unsigned char* data =(unsigned char*)malloc(tcp_file_head.compress_size_); input_file_stream.read((char*)data,tcp_file_head.compress_size_); input_file_stream.close(); stopwatch.stop(); std::int64_t decompress_jpg_cost = stopwatch.milliseconds(); texture2d->gl_texture_format_=tcp_file_head.gl_texture_format_; texture2d->width_=tcp_file_head.width_; texture2d->height_=tcp_file_head.height_; delete (data); return texture2d; } 在main.cpp 修改读取文件为urban.cpt： int main(void) { init_opengl(); CreateTexture(\"../data/images/urban.cpt\"); ...... } 调试查看数据： 正常读取到cpt文件头信息，而且解析cpt文件耗时仅6ms！ 2. 上传cpt压缩纹理数据并渲染 从cpt文件读取到文件头和压缩纹理数据之后，就可以上传到GPU进行渲染。 Texture2D* Texture2D::LoadFromFile(std::string& image_file_path) { ...... //1. 通知显卡创建纹理对象，返回句柄; glGenTextures(1, &(texture2d->gl_texture_id_)); //2. 将纹理绑定到特定纹理目标; glBindTexture(GL_TEXTURE_2D, texture2d->gl_texture_id_); stopwatch.restart(); { //3. 将压缩纹理数据上传到GPU; glCompressedTexImage2D(GL_TEXTURE_2D, 0, texture2d->gl_texture_format_, texture2d->width_, texture2d->height_, 0, tcp_file_head.compress_size_, data); } stopwatch.stop(); std::int64_t upload_cpt_cost = stopwatch.milliseconds(); //4. 指定放大，缩小滤波方式，线性滤波，即放大缩小的插值方式; glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR); delete (data); return texture2d; } 和之前使用.jpg图片类似，唯一不同的是，这次我们上传的是压缩纹理数据，需要使用新的API：glCompressedTexImage2D，下面看介绍。 /** * @brief 将压缩纹理数据上传到GPU; * @param target 目标纹理，GL_TEXTURE_2D(2D纹理) * @param level 当图片数据是包含多个mipmap层级时，指定使用mipmap层级。 * @param internalformat 上传的压缩纹理数据格式 * @param width * @param height * @param border * @param imageSize 上传的压缩纹理数据字节数 * @param data 上传的数据 * @return */ void glCompressedTexImage2D(GLenum target, GLint level, GLenum internalformat, GLsizei width, GLsizei height, GLint border, GLsizei imageSize, const void * data); 需要注意 internalformat，一定要和图片压缩后OpenGL返回的压缩格式保持一致，不然会出现错误。 编译运行，正常渲染了立方体： 3. 性能提升对比 断点调试查看耗时，如图: 与使用.jpg文件进行对比： 解析耗时(ms)上传耗时(ms) jpg1571960 cpt416 有很大的性能提升。 回顾一下，我们是先将.jpg图片，解析得到RGB数据，上传到GPU进行压缩，然后再从GPU下载压缩纹理数据，保存为.cpt文件。 这其实就是Unity导入图片的时候干的活，现在你知道为什么Unity导入图片那么慢了！ Copyright © captainchen all right reserved，powered by GitbookFile Modify: 2021-04-20 10:37:38 "},"pages/6. 索引与缓冲区对象/6. 缓冲区对象.html":{"url":"pages/6. 索引与缓冲区对象/6. 缓冲区对象.html","title":"6. 缓冲区对象","keywords":"","body":"6. 缓冲区对象6. 缓冲区对象 在之前的章节实例，引擎主循环每执行一次，都需要上传顶点数据到GPU。 这在实际项目中是不可行的，游戏同屏顶点数普遍超过10w，每一帧都上传10w顶点数据到GPU，想想都可怕。 针对性的优化有2点： 减少上传数据量 在GPU上缓存数据 OpenGL分别提供了对应的技术来实现上面的优化，就是顶点索引和缓冲区对象，这一章围绕着这两点进行开发实践。 Copyright © captainchen all right reserved，powered by GitbookFile Modify: 2021-04-26 14:49:02 "},"pages/6. 索引与缓冲区对象/6.1 顶点索引.html":{"url":"pages/6. 索引与缓冲区对象/6.1 顶点索引.html","title":"6.1 顶点索引","keywords":"","body":"6.1 顶点索引1. 何为顶点索引2. 何为顶点？3. 使用顶点索引绘制立方体6.1 顶点索引 回顾3.2 画个正方形 这一章的实例，绘制一个正方形，需要上传6个顶点数据到GPU。 但是我们都知道，实际上只有4个顶点数据。只是为了凑成2个三角形，将这4个顶点分为了 3 3 两份。 重复的顶点不仅增加了上传到GPU的数据量，也增加了GPU顶点着色器的执行次数(每个顶点执行一次)。 OpenGL提供了新的机制 - 顶点索引，来进行优化。 1. 何为顶点索引 从实例代码中也可以看到，顶点坐标数据一个个数组，那么顶点索引就是这个数组的index。 以正方形的顶点坐标数据为例： static const glm::vec3 Positions[6] = { //第一个三角形 { -1.0f, -1.0f, 0.0f},//左下 { 1.0f, -1.0f, 0.0f},//右下 { 1.0f, 1.0f, 0.0f},//右上 //第二个三角形 { 1.0f, 1.0f, 0.0f},//右上 { -1.0f, -1.0f, 0.0f},//左上 { -1.0f, 1.0f, 0.0f}//左下 }; 去掉重复，实际上只有4个顶点： static const glm::vec3 Positions[4] = { { -1.0f, -1.0f, 0.0f},//左下 { 1.0f, -1.0f, 0.0f},//右下 { 1.0f, 1.0f, 0.0f},//右上 { -1.0f, -1.0f, 0.0f},//左上 }; 这4个顶点，要怎么组成2个三角形呢？ 去重后顶点坐标数据不可以重复，但是可以新建一个数组，存储重复的顶点索引。 static const glm::vec3 indices[6] = { //第一个三角形 0,1,2, //第二个三角形 2,3,1 }; 借助顶点索引数组，间接地组成了2个三角形。 2. 何为顶点？ 本段落CLion项目文件位于 samples\\vertex_index_and_buffer\\vertex 上面说了，将顶点坐标去重，然后新建数组存储下标，那么顶点颜色和UV坐标怎么处理呢？ 这里我们要明确一个概念 -- 顶点是什么？ 一个顶点，包含了顶点坐标、顶点颜色、UV坐标这三个数据。 三者任意之一不同，那么就是2个不同的顶点。 所以使用顶点索引需要进行去重，是去掉三者完全相同的顶点。 为了更深入理解顶点概念，对vertex_data.h进行修改，引入struct Vertex，并将之前的顶点坐标(kPositions)、顶点颜色(kColors)、UV坐标(kUvs)这三个数据合并为顶点(kVertexs)。 //顶点 struct Vertex { glm::vec3 pos_; glm::vec4 color_; glm::vec2 uv_; }; static const Vertex kVertexs[36] ={ //Front glm::vec3(-1.0f, -1.0f, 1.0f), glm::vec4(1.0f,1.0f,1.0f,1.0f), glm::vec2(0.0f, 0.0f), glm::vec3( 1.0f, -1.0f, 1.0f), glm::vec4(1.0f,1.0f,1.0f,1.0f), glm::vec2(1.0f, 0.0f), glm::vec3( 1.0f, 1.0f, 1.0f), glm::vec4(1.0f,1.0f,1.0f,1.0f), glm::vec2(1.0f, 1.0f), glm::vec3(-1.0f, -1.0f, 1.0f), glm::vec4(1.0f,1.0f,1.0f,1.0f), glm::vec2(0.0f, 0.0f), glm::vec3( 1.0f, 1.0f, 1.0f), glm::vec4(1.0f,1.0f,1.0f,1.0f), glm::vec2(1.0f, 1.0f), glm::vec3(-1.0f, 1.0f, 1.0f), glm::vec4(1.0f,1.0f,1.0f,1.0f), glm::vec2(0.0f, 1.0f), //back glm::vec3(-1.0f, -1.0f, -1.0f), glm::vec4(1.0f,1.0f,1.0f,1.0f), glm::vec2(0.0f, 0.0f), ...... }; 然后在将顶点数据与顶点Shader属性进行关联时，需要加上指针偏移，代码如下： //main.cpp //启用顶点Shader属性(a_pos)，指定与顶点坐标数据进行关联 glEnableVertexAttribArray(vpos_location); glVertexAttribPointer(vpos_location, 3, GL_FLOAT, false, sizeof(Vertex), kVertexs); //启用顶点Shader属性(a_color)，指定与顶点颜色数据进行关联 glEnableVertexAttribArray(vcol_location); glVertexAttribPointer(vcol_location, 4, GL_FLOAT, false, sizeof(Vertex), ((float*)kVertexs) + 3); //启用顶点Shader属性(a_uv)，指定与顶点UV数据进行关联 glEnableVertexAttribArray(a_uv_location); glVertexAttribPointer(a_uv_location, 2, GL_FLOAT, false, sizeof(Vertex), ((float*)kVertexs) + 3 + 4); 代码修改后，模糊掉了顶点坐标、顶点颜色、UV坐标这三个数据，面对的就是顶点这个整体。 3. 使用顶点索引绘制立方体 下面就在上一段落的实例项目基础之上，使用顶点索引绘制立方体。 CLion项目文件位于 samples\\vertex_index_and_buffer\\indices 3.1 去除重复顶点 上一段落的实例项目，存有36个顶点在kVertexs[36]中，首先编写代码将顶点数据去重： //vertex_data.h //去重的顶点Vector static vector kVertexRemoveDumplicateVector; //顶点索引Vector static vector kVertexIndexVector; //顶点去重 static void VertexRemoveDumplicate(){ for (int i = 0; i 断点调试，发现顶点去重后只剩下16个，节省了一大半内存。 后续渲染就使用去重后的顶点数据(kVertexRemoveDumplicateVector) 和 顶点索引(kVertexIndexVector)。 3.2 使用顶点索引绘制 首先将去重后的顶点数据(kVertexRemoveDumplicateVector)与Shader属性进行绑定: //启用顶点Shader属性(a_pos)，指定与顶点坐标数据进行关联 glVertexAttribPointer(vpos_location, 3, GL_FLOAT, false, sizeof(Vertex), (float*)(&kVertexRemoveDumplicateVector[0])); //启用顶点Shader属性(a_color)，指定与顶点颜色数据进行关联 glVertexAttribPointer(vcol_location, 4, GL_FLOAT, false, sizeof(Vertex), ((float*)(&kVertexRemoveDumplicateVector[0]) + 3)); //顶启用顶点Shader属性(a_uv)，指定与点UV数据进行关联 glVertexAttribPointer(a_uv_location, 2, GL_FLOAT, false, sizeof(Vertex), ((float*)(&kVertexRemoveDumplicateVector[0]) + 3 + 4)); 然后使用顶点索引(kVertexIndexVector)进行绘制，需要引入新的API - glDrawElements。 void glDrawElements(GLenum mode,GLsizei count,GLenum type,const void * indices); 参数解析： mode 几何图元类型，可选 GL_POINT(点)、GL_LINE(线)、GL_TRIANGLES(三角形) count 几何图元数量 type 索引数据类型 indices 索引数组 将原来的代码修改为： //glDrawArrays(GL_TRIANGLES, 0, 6*6);//表示从第0个顶点开始画，总共画6个面，每个面6个顶点。 glDrawElements(GL_TRIANGLES,36,GL_UNSIGNED_SHORT,(float*)(&kVertexIndexVector[0]));//使用顶点索引进行绘制。 再次编译运行，结果正常： Copyright © captainchen all right reserved，powered by GitbookFile Modify: 2021-04-26 14:49:02 "},"pages/6. 索引与缓冲区对象/6.2 缓冲区对象.html":{"url":"pages/6. 索引与缓冲区对象/6.2 缓冲区对象.html","title":"6.2 缓冲区对象","keywords":"","body":"6.2 缓冲区对象1. 创建VBO和EBO，并上传数据2. 将Shader变量和缓冲区对象进行关联3. 绘制6.2 缓冲区对象 CLion项目文件位于 samples\\vertex_index_and_buffer\\vbo 上一节使用 glDrawElements 通过顶点索引进行绘制，大幅度减少了上传到GPU的数据，但是仍然是每一帧都上传一次。 是否可以将数据缓存在GPU，这样只需要上传一次即可？ OpenGL引入了Buffer Object，即缓冲区对象。 在之前的例子，顶点数据和顶点索引的流向如下图： 从硬盘读取模型数据，拷贝到内存中，然后每次绘制的时候上传到显卡。 平时玩游戏的时候，每过一个场景，都会打开一个 Loading 界面，在Loading 界面出现的时候，就是从硬盘中读取顶点数据到设备内存中。 当要渲染的时候，就直接从内存中把顶点数据读取出来，然后上传到显卡的显存中。 使用缓冲区对象之后，如下图： 顶点数据上传到GPU之后，就缓存起来，后续渲染直接从显存获取。 使用缓冲区对象进行绘制分为以下步骤： 创建VBO(顶点缓冲区对象) 和 EBO(索引缓冲区对象)，并上传数据 将Shader变量和缓冲区对象进行关联 使用EBO绘制 下面一一来看。 1. 创建VBO和EBO，并上传数据 //main.cpp //创建VBO和EBO void GeneratorBufferObject() { //在GPU上创建缓冲区对象 glGenBuffers(1,&kVBO); //将缓冲区对象指定为顶点缓冲区对象 glBindBuffer(GL_ARRAY_BUFFER, kVBO); //上传顶点数据到缓冲区对象 glBufferData(GL_ARRAY_BUFFER, kVertexRemoveDumplicateVector.size() * sizeof(Vertex), &kVertexRemoveDumplicateVector[0], GL_STATIC_DRAW); //在GPU上创建缓冲区对象 glGenBuffers(1,&kEBO); //将缓冲区对象指定为顶点索引缓冲区对象 glBindBuffer(GL_ELEMENT_ARRAY_BUFFER, kEBO); //上传顶点索引数据到缓冲区对象 glBufferData(GL_ELEMENT_ARRAY_BUFFER, kVertexIndexVector.size() * sizeof(unsigned short), &kVertexIndexVector[0], GL_STATIC_DRAW); } 在GPU上创建对象，都是分三步，调用3个API： glGenxxxx 在GPU上进行创建xx对象 glBindxxx 将xx对象指定为类型 glxxxxxxx 上传数据 与创建纹理对象进行对比： 步骤纹理VBO 1glGenTextures通知显卡创建纹理对象glGenBuffers在GPU创建缓冲区对象 2glBindTexture将纹理绑定到特定纹理目标glBindBuffer将缓冲区对象指定为顶点索引缓冲区对象 3glTexImage2D将图片rgb数据上传到GPU;glBufferData上传顶点索引数据到缓冲区对象 简单介绍这3个API： /** *@brief 在GPU上创建缓冲区对象 *@param n 创建个数 *@param buffers 缓冲区句柄 */ void glGenBuffers(GLsizei n, GLuint * buffers); /** *@brief 将缓冲区对象指定为特定目标 *@param target 目标，常用GL_ARRAY_BUFFER(顶点属性缓冲区) GL_ELEMENT_ARRAY_BUFFER(顶点索引缓冲区) *@param buffers 缓冲区句柄 */ void glBindBuffer(GLenum target, GLuint buffer); /** *@brief 将缓冲区对象指定为特定目标 *@param target 目标，常用GL_ARRAY_BUFFER(顶点属性缓冲区) GL_ELEMENT_ARRAY_BUFFER(顶点索引缓冲区) *@param size 顶点索引数据size *@param data 顶点索引数组 *@param usage 缓冲区使用方式，常用GL_STATIC_DRAW(仅修改一次后重复使用) */ void glBufferData(GLenum target, GLsizeiptr size, const void * data, GLenum usage); 2. 将Shader变量和缓冲区对象进行关联 之前是直接将顶点属性数据和Shader变量进行关联，代码如下： //启用顶点Shader属性(a_pos)，指定与顶点坐标数据进行关联 glVertexAttribPointer(vpos_location, 3, GL_FLOAT, false, sizeof(glm::vec3), kPositions); //顶启用顶点Shader属性(a_uv)，指定与点UV数据进行关联 glVertexAttribPointer(a_uv_location, 2, GL_FLOAT, false, sizeof(glm::vec2), kUvs); 现在数据都上传到VBO了，那么就需要将Shader变量和缓冲区对象句柄进行关联，代码修改如下： //指定当前使用的VBO glBindBuffer(GL_ARRAY_BUFFER, kVBO); //将Shader变量(a_pos)和顶点坐标VBO句柄进行关联，最后的0表示数据偏移量。 glVertexAttribPointer(vpos_location, 3, GL_FLOAT, false, sizeof(Vertex), 0); //启用顶点Shader属性(a_color)，指定与顶点颜色数据进行关联 glVertexAttribPointer(vcol_location, 4, GL_FLOAT, false, sizeof(Vertex), (void*)(sizeof(float)*3)); //将Shader变量(a_uv)和顶点UV坐标VBO句柄进行关联，最后的0表示数据偏移量。 glVertexAttribPointer(a_uv_location, 2, GL_FLOAT, false, sizeof(Vertex), (void*)(sizeof(float)*(3+4))); 函数glVertexAttribPointer 最后的参数由顶点属性数组变为了数据偏移量。 数据关联好之后，就可以进行绘制了。 3. 绘制 上一节使用顶点索引进行绘制时，需要在glDrawElements中传入顶点索引数据，每Draw一次都上传一次索引到GPU。 glDrawElements(GL_TRIANGLES,36,GL_UNSIGNED_SHORT,kIndices);//使用顶点索引进行绘制。 现在顶点索引数据都上传到EBO了，就只需要指定当前使用的EBO，然后直接绘制。 //指定当前使用的顶点索引缓冲区对象 glBindBuffer(GL_ELEMENT_ARRAY_BUFFER, kEBO); glDrawElements(GL_TRIANGLES,36,GL_UNSIGNED_SHORT,0);//使用顶点索引进行绘制，最后的0表示数据偏移量。 编译运行，效果正确： Copyright © captainchen all right reserved，powered by GitbookFile Modify: 2021-04-26 14:49:02 "},"pages/7. Mesh和材质/7. Mesh和材质.html":{"url":"pages/7. Mesh和材质/7. Mesh和材质.html","title":"7. Mesh和材质","keywords":"","body":"7. Mesh和材质7. Mesh和材质 在之前的实例，渲染所需要的数据都是写死在代码中，这样太不专业。 这一章节将渲染数据进行拆分存储，顶点数据存储为.Mesh文件，顶点Shader代码存储为.vs文件，片段Shader代码存储为.fs文件，图片路径信息存储为.mat材质文件。 这样只需要修改.mat材质内容就可以产生不同的效果，就像在Unity中更换材质、选择Shader、更换贴图一样。 Copyright © captainchen all right reserved，powered by GitbookFile Modify: 2021-04-20 13:27:00 "},"pages/7. Mesh和材质/7.1 导出Mesh文件.html":{"url":"pages/7. Mesh和材质/7.1 导出Mesh文件.html","title":"7.1 导出Mesh文件","keywords":"","body":"7.1 导出Mesh文件1. Mesh文件格式2. 导出文件7.1 导出Mesh文件 CLion项目文件位于 samples\\mesh_and_material\\export_mesh_file 这一节将写死在vertex_data.h中的立方体顶点数据，存放到自定义格式的.mesh文件中。 1. Mesh文件格式 .mesh文件格式如下： 文件头 顶点个数 索引个数 顶点数据 索引数据 2. 导出文件 按照上面的Mesh文件格式，在vertex_data.h中新增函数ExportMesh导出立方体的顶点数据和索引数据。 //vertex_data.h //Mesh文件头 struct MeshFileHead{ char type_[4]; int vertex_num_;//顶点个数 int vertex_index_num_;//索引个数 }; //导出Mesh文件 static void ExportMesh(string save_path){ ofstream output_file_stream(save_path,ios::out | ios::binary); MeshFileHead mesh_file_head; mesh_file_head.type_[0]='m'; mesh_file_head.type_[1]='e'; mesh_file_head.type_[2]='s'; mesh_file_head.type_[3]='h'; mesh_file_head.vertex_num_=kVertexRemoveDumplicateVector.size(); mesh_file_head.vertex_index_num_=kVertexIndexVector.size(); //写入文件头 output_file_stream.write((char*)&mesh_file_head, sizeof(mesh_file_head)); //写入顶点数据 output_file_stream.write((char*)&kVertexRemoveDumplicateVector[0],kVertexRemoveDumplicateVector.size()*sizeof(Vertex)); //写入索引数据 output_file_stream.write((char*)&kVertexIndexVector[0],kVertexIndexVector.size()*sizeof(unsigned short)); output_file_stream.close(); } 在main.cpp中调用： int main(void) { VertexRemoveDumplicate(); ExportMesh(\"../data/model/cube.mesh\"); return 0; ...... } 编译运行，生成了文件cube.mesh，拖到十六进制编辑器中查看： Copyright © captainchen all right reserved，powered by GitbookFile Modify: 2021-04-26 14:49:02 "},"pages/7. Mesh和材质/7.2 使用Mesh文件.html":{"url":"pages/7. Mesh和材质/7.2 使用Mesh文件.html","title":"7.2 使用Mesh文件","keywords":"","body":"7.2 使用Mesh文件1. 加载Mesh2. 使用Mesh渲染7.2 使用Mesh文件 CLion项目文件位于 samples\\mesh_and_material\\export_mesh_file 顶点数据和索引数据已经存放在.mesh文件中，vertex_data.h可以删除了。 现在需要做的是，编写代码将cube.mesh加载到内存，然后用于渲染。 1. 加载Mesh 这里参考Unity的命名，创建类 MeshFilter负责Mesh的加载与管理，代码文件是mesh_filter.h。 将加载Mesh文件的数据存放在名为Mesh的结构体中。 //Mesh数据 struct Mesh{ unsigned short vertex_num_;//顶点个数 unsigned short vertex_index_num_;//索引个数 Vertex* vertex_data_;//顶点数据 unsigned short* vertex_index_data_;//顶点索引数据 }; 加载Mesh文件代码如下： //mesh_filter.cpp void MeshFilter::LoadMesh(string mesh_file_path) { //读取 Mesh文件头 ifstream input_file_stream(mesh_file_path,ios::in | ios::binary); MeshFileHead mesh_file_head; input_file_stream.read((char*)&mesh_file_head,sizeof(mesh_file_head)); //读取顶点数据 unsigned char* vertex_data =(unsigned char*)malloc(mesh_file_head.vertex_num_*sizeof(Vertex)); input_file_stream.read((char*)vertex_data,mesh_file_head.vertex_num_*sizeof(Vertex)); //读取顶点索引数据 unsigned short* vertex_index_data=(unsigned short*)malloc(mesh_file_head.vertex_index_num_*sizeof(unsigned short)); input_file_stream.read((char*)vertex_index_data,mesh_file_head.vertex_index_num_*sizeof(unsigned short)); input_file_stream.close(); mesh_=new Mesh(); mesh_->vertex_num_=mesh_file_head.vertex_num_; mesh_->vertex_index_num_=mesh_file_head.vertex_index_num_; mesh_->vertex_data_=(Vertex*)vertex_data; mesh_->vertex_index_data_=vertex_index_data; } 成功加载后，顶点数据和索引数据就存放在成员变量mesh_中，后续只需要调用接口mesh()就可以获得。 //mesh_filter.h Mesh* mesh(){return mesh_;};//Mesh对象 2. 使用Mesh渲染 只需要在创建缓冲区对象时，指定为Mesh数据即可。 //main.cpp //创建VBO和EBO void GeneratorBufferObject() { //在GPU上创建缓冲区对象 glGenBuffers(1,&kVBO); //将缓冲区对象指定为顶点缓冲区对象 glBindBuffer(GL_ARRAY_BUFFER, kVBO); //上传顶点数据到缓冲区对象 glBufferData(GL_ARRAY_BUFFER, mesh_filter->mesh()->vertex_num_ * sizeof(MeshFilter::Vertex), mesh_filter->mesh()->vertex_data_, GL_STATIC_DRAW); //在GPU上创建缓冲区对象 glGenBuffers(1,&kEBO); //将缓冲区对象指定为顶点索引缓冲区对象 glBindBuffer(GL_ELEMENT_ARRAY_BUFFER, kEBO); //上传顶点索引数据到缓冲区对象 glBufferData(GL_ELEMENT_ARRAY_BUFFER, mesh_filter->mesh()->vertex_index_num_ * sizeof(unsigned short), mesh_filter->mesh()->vertex_index_data_, GL_STATIC_DRAW); } 编译运行，一切正常: Copyright © captainchen all right reserved，powered by GitbookFile Modify: 2021-04-26 14:49:02 "},"pages/7. Mesh和材质/7.3 Shader文件创建与使用.html":{"url":"pages/7. Mesh和材质/7.3 Shader文件创建与使用.html","title":"7.3 Shader文件创建与使用","keywords":"","body":"7.3 Shader文件创建与使用1. 创建Shader文件2. 加载Shader文件7.3 Shader文件创建与使用 我们知道，Shader分为Vertex Shader(顶点Shader)和Fragment Shader(片段Shader)，之前项目的Shader代码是写死在shader_source.h，现在就将它们分别存放到.vs和.fs文件中。 1. 创建Shader文件 创建Unlit.vs 和 Unlit.fs，将shader_source.h中的Shader代码放进去。 2. 加载Shader文件 编写代码加载Shader文件，然后编译、创建Shader程序、Link。 Copyright © captainchen all right reserved，powered by GitbookFile Modify: 2021-04-28 11:10:29 "}}